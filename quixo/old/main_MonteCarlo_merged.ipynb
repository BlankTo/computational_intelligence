{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from game import Game, Move, Player\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy_Game(object):\n",
    "    def __init__(self) -> None:\n",
    "        self._board = np.ones((5, 5), dtype=np.uint8) * -1\n",
    "        self.current_player_idx = 1\n",
    "\n",
    "    def get_board(self): return self._board\n",
    "\n",
    "    def single_move(self, board, from_pos, move, player_id):\n",
    "        self._board = deepcopy(board)\n",
    "        self.current_player_idx = player_id\n",
    "        ok = self.__move(from_pos, move, player_id)\n",
    "        return deepcopy(self._board), ok\n",
    "    \n",
    "    def check_winner_board(self, board):\n",
    "        self._board = board\n",
    "        return self.check_winner()\n",
    "\n",
    "    def check_winner(self) -> int:\n",
    "        for x in range(self._board.shape[0]):\n",
    "            if self._board[x, 0] != -1 and all(self._board[x, :] == self._board[x, 0]): return self._board[x, 0]\n",
    "        for y in range(self._board.shape[1]):\n",
    "            if self._board[0, y] != -1 and all(self._board[:, y] == self._board[0, y]): return self._board[0, y]\n",
    "        if self._board[0, 0] != -1 and all([self._board[x, x] for x in range(self._board.shape[0])] == self._board[0, 0]): return self._board[0, 0]\n",
    "        if self._board[0, -1] != -1 and all([self._board[x, -(x + 1)] for x in range(self._board.shape[0])] == self._board[0, -1]): return self._board[0, -1]\n",
    "        return -1\n",
    "\n",
    "    def __move(self, from_pos: tuple[int, int], slide: Move, player_id: int) -> bool:\n",
    "        if player_id > 2: return False\n",
    "        prev_value = deepcopy(self._board[(from_pos[1], from_pos[0])])\n",
    "        acceptable = self.__take((from_pos[1], from_pos[0]), player_id)\n",
    "        if acceptable:\n",
    "            acceptable = self.__slide((from_pos[1], from_pos[0]), slide)\n",
    "            if not acceptable: self._board[(from_pos[1], from_pos[0])] = deepcopy(prev_value)\n",
    "        return acceptable\n",
    "\n",
    "    def __take(self, from_pos: tuple[int, int], player_id: int) -> bool:\n",
    "        acceptable: bool = ((from_pos[0] == 0 and from_pos[1] < 5) or (from_pos[0] == 4 and from_pos[1] < 5) or (from_pos[1] == 0 and from_pos[0] < 5) or (from_pos[1] == 4 and from_pos[0] < 5)) and (self._board[from_pos] < 0 or self._board[from_pos] == player_id)\n",
    "        if acceptable: self._board[from_pos] = player_id\n",
    "        return acceptable\n",
    "\n",
    "    def __slide(self, from_pos: tuple[int, int], slide: Move) -> bool:\n",
    "        SIDES = [(0, 0), (0, 4), (4, 0), (4, 4)]\n",
    "        if from_pos not in SIDES:\n",
    "            acceptable_top: bool = from_pos[0] == 0 and (slide == Move.BOTTOM or slide == Move.LEFT or slide == Move.RIGHT)\n",
    "            acceptable_bottom: bool = from_pos[0] == 4 and (slide == Move.TOP or slide == Move.LEFT or slide == Move.RIGHT)\n",
    "            acceptable_left: bool = from_pos[1] == 0 and (slide == Move.BOTTOM or slide == Move.TOP or slide == Move.RIGHT)\n",
    "            acceptable_right: bool = from_pos[1] == 4 and (slide == Move.BOTTOM or slide == Move.TOP or slide == Move.LEFT)\n",
    "        else:\n",
    "            acceptable_top: bool = from_pos == (0, 0) and (slide == Move.BOTTOM or slide == Move.RIGHT)\n",
    "            acceptable_left: bool = from_pos == (4, 0) and (slide == Move.TOP or slide == Move.RIGHT)\n",
    "            acceptable_right: bool = from_pos == (0, 4) and (slide == Move.BOTTOM or slide == Move.LEFT)\n",
    "            acceptable_bottom: bool = from_pos == (4, 4) and (slide == Move.TOP or slide == Move.LEFT)\n",
    "        acceptable: bool = acceptable_top or acceptable_bottom or acceptable_left or acceptable_right\n",
    "        if acceptable:\n",
    "            piece = self._board[from_pos]\n",
    "            if slide == Move.LEFT:\n",
    "                for i in range(from_pos[1], 0, -1): self._board[(from_pos[0], i)] = self._board[(from_pos[0], i - 1)]\n",
    "                self._board[(from_pos[0], 0)] = piece\n",
    "            elif slide == Move.RIGHT:\n",
    "                for i in range(from_pos[1], self._board.shape[1] - 1, 1): self._board[(from_pos[0], i)] = self._board[(from_pos[0], i + 1)]\n",
    "                self._board[(from_pos[0], self._board.shape[1] - 1)] = piece\n",
    "            elif slide == Move.TOP:\n",
    "                for i in range(from_pos[0], 0, -1): self._board[(i, from_pos[1])] = self._board[(i - 1, from_pos[1])]\n",
    "                self._board[(0, from_pos[1])] = piece\n",
    "            elif slide == Move.BOTTOM:\n",
    "                for i in range(from_pos[0], self._board.shape[0] - 1, 1): self._board[(i, from_pos[1])] = self._board[(i + 1, from_pos[1])]\n",
    "                self._board[(self._board.shape[0] - 1, from_pos[1])] = piece\n",
    "        return acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "border = []\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i == 0 or i == 4 or j == 0 or j == 4:\n",
    "            border.append((i, j))\n",
    "BORDER = (list(set(border)))\n",
    "print(len(BORDER))\n",
    "\n",
    "def tile_to_moves(tile):\n",
    "    possible_moves = [Move.TOP, Move.BOTTOM, Move.LEFT, Move.RIGHT]\n",
    "        \n",
    "    if tile[0] == 0: possible_moves.remove(Move.LEFT)\n",
    "    if tile[0] == 4: possible_moves.remove(Move.RIGHT)\n",
    "    if tile[1] == 0: possible_moves.remove(Move.TOP)\n",
    "    if tile[1] == 4: possible_moves.remove(Move.BOTTOM)\n",
    "\n",
    "    return possible_moves\n",
    "\n",
    "tile_moves = {tile: tile_to_moves(tile) for tile in BORDER}\n",
    "\n",
    "ALL_MOVES = []\n",
    "for tile in BORDER:\n",
    "    possible_moves = tile_moves[tile]\n",
    "    for move in possible_moves: ALL_MOVES.append((tile, move))\n",
    "N_ALL = len(ALL_MOVES)\n",
    "\n",
    "class RandomPlayer(Player):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        from_pos = random.choice(BORDER)\n",
    "        while game.get_board()[from_pos[1], from_pos[0]] == 1 - game.current_player_idx: from_pos = random.choice(BORDER)\n",
    "\n",
    "        possible_moves = tile_moves[from_pos]\n",
    "        \n",
    "        move = random.choice(possible_moves)\n",
    "\n",
    "        return from_pos, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## state can be represented as two numbers if 0,1 are considered as bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[[-1  0 -1  0  0]\n",
      " [ 0  0 -1  0  0]\n",
      " [ 0  1 -1  1  1]\n",
      " [-1  0  0  1  1]\n",
      " [ 1 -1 -1  0  0]]\n",
      "\n",
      "State:\n",
      "708240509774960\n",
      "\n",
      "Board:\n",
      "[[-1  0 -1  0  0]\n",
      " [ 0  0 -1  0  0]\n",
      " [ 0  1 -1  1  1]\n",
      " [-1  0  0  1  1]\n",
      " [ 1 -1 -1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def state_to_board(state):\n",
    "    binary_string = format(state, '050b')\n",
    "    binary_array = np.array(list(map(int, binary_string))).reshape(2, 5, 5)\n",
    "\n",
    "    board = np.zeros((5, 5), dtype=int)\n",
    "    board[binary_array[0] == 1] = -1\n",
    "    board[binary_array[1] == 1] = 1\n",
    "\n",
    "    return board\n",
    "\n",
    "def board_to_state(board):\n",
    "    binary_array = np.zeros((2, 5, 5), dtype=int)\n",
    "    \n",
    "    binary_array[0][board == -1] = 1\n",
    "    binary_array[1][board == 1] = 1\n",
    "\n",
    "    binary_string = ''.join(map(str, binary_array.flatten()))\n",
    "    return int(binary_string, 2)\n",
    "\n",
    "\n",
    "\n",
    "rand_board = np.random.choice([-1, 0, 1], size=(5, 5), replace=True)\n",
    "print('Board:')\n",
    "print(rand_board)\n",
    "\n",
    "rand_state = board_to_state(rand_board)\n",
    "rand_board = state_to_board(rand_state)\n",
    "\n",
    "print('\\nState:')\n",
    "print(rand_state)\n",
    "print('\\nBoard:')\n",
    "print(state_to_board(rand_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "dict_rot = {\n",
    "    (Move.TOP, 1): Move.LEFT,\n",
    "    (Move.TOP, 2): Move.BOTTOM,\n",
    "    (Move.TOP, 3): Move.RIGHT,\n",
    "    (Move.BOTTOM, 1): Move.RIGHT,\n",
    "    (Move.BOTTOM, 2): Move.TOP,\n",
    "    (Move.BOTTOM, 3): Move.LEFT,\n",
    "    (Move.LEFT, 1): Move.TOP,\n",
    "    (Move.LEFT, 2): Move.RIGHT,\n",
    "    (Move.LEFT, 3): Move.BOTTOM,\n",
    "    (Move.RIGHT, 1): Move.BOTTOM,\n",
    "    (Move.RIGHT, 2): Move.LEFT,\n",
    "    (Move.RIGHT, 3): Move.TOP,\n",
    "}\n",
    "\n",
    "dict_flip = {\n",
    "    Move.TOP: Move.TOP,\n",
    "    Move.BOTTOM: Move.BOTTOM,\n",
    "    Move.LEFT: Move.RIGHT,\n",
    "    Move.RIGHT: Move.LEFT,\n",
    "}\n",
    "\n",
    "#rot_orario: (3, 4) -> (4, 1) -> (1, 0) -> (0, 3) -> (3, 4)\n",
    "#: (xi, yi) -> (yi, 4 - xi)\n",
    "#rot_anti_orario: (3, 4) -> (0, 3) -> (1, 0) -> (4, 1) -> (3, 4)\n",
    "#: (xi, yi) -> (4 - yi, xi)\n",
    "\n",
    "def rot(n_rot):\n",
    "    def rot_n(from_pos, move):\n",
    "        for _ in range(n_rot):\n",
    "            from_pos = 4 - from_pos[1], from_pos[0]\n",
    "        return from_pos, dict_rot[(move, n_rot)]\n",
    "    return rot_n\n",
    "\n",
    "def flip(from_pos, move):\n",
    "    from_pos = 4 - from_pos[0], from_pos[1]\n",
    "    return from_pos, dict_flip[move]\n",
    "\n",
    "def flip_rot(n_rot):\n",
    "    def flip_rot_n(from_pos, move):\n",
    "        from_pos, move = rot(n_rot)(from_pos, move)\n",
    "        return flip(from_pos, move)\n",
    "    return flip_rot_n\n",
    "\n",
    "rot1 = rot(1)\n",
    "rot2 = rot(2)\n",
    "rot3 = rot(3)\n",
    "flip_rot1 = flip_rot(1)\n",
    "flip_rot2 = flip_rot(2)\n",
    "flip_rot3 = flip_rot(3)\n",
    "\n",
    "verse_simmetries = [\n",
    "    rot3,\n",
    "    rot2,\n",
    "    rot1,\n",
    "    flip,\n",
    "    flip_rot3,\n",
    "    flip_rot2,\n",
    "    flip_rot1,\n",
    "]\n",
    "\n",
    "inverse_simmetries = [\n",
    "    rot1,\n",
    "    rot2,\n",
    "    rot3,\n",
    "    flip,\n",
    "    flip_rot1,\n",
    "    flip_rot2,\n",
    "    flip_rot3,\n",
    "]\n",
    "\n",
    "def check_simmetries(board, state_list):\n",
    "\n",
    "    if tuple(board.flatten()) in state_list: return tuple(board.flatten()), None\n",
    "\n",
    "    R1 = np.rot90(board)\n",
    "    if tuple(R1.flatten()) in state_list: return tuple(R1.flatten()), 0\n",
    "\n",
    "    R2 = np.rot90(R1)\n",
    "    if tuple(R2.flatten()) in state_list: return tuple(R2.flatten()), 1\n",
    "\n",
    "    R3 = np.rot90(R2)\n",
    "    if tuple(R3.flatten()) in state_list: return tuple(R3.flatten()), 2\n",
    "    \n",
    "    F = np.fliplr(board)\n",
    "    if tuple(F.flatten()) in state_list: return tuple(F.flatten()), 3\n",
    "    \n",
    "    FR1 = np.rot90(F)\n",
    "    if tuple(FR1.flatten()) in state_list: return tuple(FR1.flatten()), 4\n",
    "    \n",
    "    FR2 = np.rot90(FR1)\n",
    "    if tuple(FR2.flatten()) in state_list: return tuple(FR2.flatten()), 5\n",
    "    \n",
    "    FR3 = np.rot90(FR2)\n",
    "    if tuple(FR3.flatten()) in state_list: return tuple(FR3.flatten()), 6\n",
    "    \n",
    "    return None\n",
    "\n",
    "MOVES_SIMMETRIES = {} #(id_move, id_simmetry) -> id_move\n",
    "\n",
    "for id_move in range(len(ALL_MOVES)):\n",
    "    from_pos, move = ALL_MOVES[id_move]\n",
    "\n",
    "    for id_simmetry in range(len(inverse_simmetries)):\n",
    "\n",
    "        idx = None\n",
    "        for i in range(len(ALL_MOVES)):\n",
    "            if ALL_MOVES[i] == inverse_simmetries[id_simmetry](from_pos, move):\n",
    "                idx = i\n",
    "                break\n",
    "        \n",
    "        MOVES_SIMMETRIES[(id_move, id_simmetry)] = i\n",
    "\n",
    "print(len(MOVES_SIMMETRIES))\n",
    "print(len(ALL_MOVES) * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPlayer(Player):\n",
    "    def __init__(self, use_simmetries= False, use_random_games= False, eps_greedy= False, eps= 2, add_sim_moves= False, add_n_moves= False, add_eval= False, alpha= 1, simulations_on_new= 1, base_until_move_change= 5) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_simmetries= use_simmetries\n",
    "\n",
    "        self.use_random_games= use_random_games\n",
    "\n",
    "        self.eps_greedy= eps_greedy\n",
    "        self.eps = eps\n",
    "\n",
    "        self.add_sim_moves= add_sim_moves\n",
    "\n",
    "        self.add_n_moves = add_n_moves\n",
    "\n",
    "        self.add_eval= add_eval\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.simulation_on_new = simulations_on_new\n",
    "\n",
    "        self.states_dict = {}\n",
    "        self.dummy = Dummy_Game()\n",
    "\n",
    "        self.base_until_move_change = base_until_move_change\n",
    "        self.last_pos_move = None\n",
    "        self.until_move_change = self.base_until_move_change\n",
    "\n",
    "        self.tot_count = 0\n",
    "        self.random_count = 0\n",
    "\n",
    "        self.expansion = self.expansion_simm if self.use_simmetries else self.expansion_no_simm\n",
    "\n",
    "        if self.add_sim_moves:\n",
    "            self.simulation = self.simulation_O_S if self.use_simmetries else self.simulation_O_no_S\n",
    "        else: self.simulation = self.simulation_no_O_no_S\n",
    "\n",
    "        self.update = self.update_add_n_moves if self.add_n_moves else self.update_norm\n",
    "\n",
    "        if self.eps_greedy: self.selection = self.selection_R_A if self.add_eval else self.selection_R_no_A\n",
    "        else: self.selection = self.selection_no_R_A if self.add_eval else self.selection_no_R_no_A\n",
    "\n",
    "        if self.use_random_games:\n",
    "            self.train_init = self.train_init_norm\n",
    "            self.train_wrapper = self.train_wrapper_rand_simm if self.use_simmetries else self.train_wrapper_rand_no_simm\n",
    "        elif self.add_sim_moves:\n",
    "            self.train_init = self.train_init_moves_simu\n",
    "            self.train_wrapper = self.train_wrapper_moves_simu\n",
    "        else:\n",
    "            self.train_init = self.train_init_norm\n",
    "            self.train_wrapper = self.train_wrapper_norm\n",
    "\n",
    "        self.train_init()\n",
    "\n",
    "    def get_random_count(self): return self.random_count\n",
    "    def get_tot_count(self): return self.tot_count\n",
    "    def reset_counters(self):\n",
    "        self.tot_count = 0\n",
    "        self.random_count = 0\n",
    "        self.until_move_change = self.base_until_move_change\n",
    "\n",
    "    def expansion_simm(self, board, next_to_move):\n",
    "\n",
    "        # get legal childrens of a node, child: (move_to_child, child_state)\n",
    "\n",
    "        children = []\n",
    "        for from_pos, move in ALL_MOVES:\n",
    "            new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "            if ok:\n",
    "                new_state = tuple(new_board.flatten())\n",
    "                \n",
    "                ######## S\n",
    "                simmetry = check_simmetries(new_board, self.states_dict)\n",
    "                if simmetry is None: id_simmetry = None\n",
    "                else: new_state, id_simmetry = simmetry\n",
    "                ######## S\n",
    "\n",
    "                children.append(((from_pos, move), new_state))\n",
    "\n",
    "        return children\n",
    "\n",
    "    def expansion_no_simm(self, board, next_to_move):\n",
    "\n",
    "        # get legal childrens of a node, child: (move_to_child, child_state)\n",
    "\n",
    "        children = []\n",
    "        for from_pos, move in ALL_MOVES:\n",
    "            new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "            if ok:\n",
    "                new_state = tuple(new_board.flatten())\n",
    "                children.append(((from_pos, move), new_state))\n",
    "\n",
    "        return children\n",
    "    \n",
    "    def simulation_no_O_no_S(self, base_board, next_to_move):\n",
    "\n",
    "        # random simulation from a certain state to the end, return outcomes\n",
    "\n",
    "        win_0 = 0\n",
    "        win_1 = 0\n",
    "\n",
    "        for _ in range(self.simulation_on_new):\n",
    "\n",
    "            next_to_play = next_to_move\n",
    "            board = deepcopy(base_board)\n",
    "\n",
    "            winner = self.dummy.check_winner_board(board)\n",
    "            while winner == -1:\n",
    "\n",
    "                from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "                while not ok:\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                    new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "\n",
    "                board = new_board\n",
    "                next_to_play = 1 - next_to_play\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            if winner == 0: win_0 += 1\n",
    "            else: win_1 += 1\n",
    "\n",
    "        return win_0, win_1, self.simulation_on_new\n",
    "\n",
    "    def simulation_O_no_S(self, base_board, next_to_move):\n",
    "\n",
    "        # random simulation from a certain state to the end, return outcomes\n",
    "\n",
    "        win_0 = 0\n",
    "        win_1 = 0\n",
    "\n",
    "        ##### O\n",
    "        path = []\n",
    "        ##### O\n",
    "\n",
    "        for _ in range(self.simulation_on_new):\n",
    "\n",
    "            next_to_play = next_to_move\n",
    "            board = deepcopy(base_board)\n",
    "\n",
    "            winner = self.dummy.check_winner_board(board)\n",
    "            while winner == -1:\n",
    "\n",
    "                from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "                while not ok:\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                    new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "\n",
    "                board = new_board\n",
    "                next_to_play = 1 - next_to_play\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "                ##### O\n",
    "                path.append(tuple(board.flatten()))\n",
    "                ##### O\n",
    "\n",
    "            if winner == 0: win_0 += 1\n",
    "            else: win_1 += 1\n",
    "        \n",
    "        ##### O\n",
    "        return path, win_0, win_1, self.simulation_on_new\n",
    "        #return win_0, win_1, self.simulation_on_new\n",
    "        ##### O\n",
    "\n",
    "    def simulation_O_S(self, base_board, next_to_move):\n",
    "\n",
    "        # random simulation from a certain state to the end, return outcomes\n",
    "\n",
    "        win_0 = 0\n",
    "        win_1 = 0\n",
    "\n",
    "        ##### O\n",
    "        path = []\n",
    "        ##### O\n",
    "\n",
    "        for _ in range(self.simulation_on_new):\n",
    "\n",
    "            next_to_play = next_to_move\n",
    "            board = deepcopy(base_board)\n",
    "\n",
    "            winner = self.dummy.check_winner_board(board)\n",
    "            while winner == -1:\n",
    "\n",
    "                from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "                while not ok:\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                    new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "\n",
    "                board = new_board\n",
    "                next_to_play = 1 - next_to_play\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "                state = tuple(board.flatten())\n",
    "\n",
    "                ######## S\n",
    "                simmetry = check_simmetries(board, self.states_dict)\n",
    "                if simmetry is not None: state, _ = simmetry\n",
    "                ######## S\n",
    "\n",
    "                ##### O\n",
    "                path.append(state)\n",
    "                ##### O\n",
    "\n",
    "            if winner == 0: win_0 += 1\n",
    "            else: win_1 += 1\n",
    "        \n",
    "        ##### O\n",
    "        return path, win_0, win_1, self.simulation_on_new\n",
    "        #return win_0, win_1, self.simulation_on_new\n",
    "        ##### O\n",
    "    \n",
    "    def update_norm(self, states_to_update, win_0, win_1, count):\n",
    "\n",
    "        player_responsible = 0\n",
    "\n",
    "        for state in states_to_update:\n",
    "            player_responsible = 1 - player_responsible\n",
    "            amount = win_0 if player_responsible == 0 else win_1\n",
    "            if state in self.states_dict:\n",
    "                self.states_dict[state][0] += amount\n",
    "                self.states_dict[state][1] += count\n",
    "            else: self.states_dict[state] = [amount, count, []]\n",
    "    \n",
    "    def update_add_n_moves(self, states_to_update, win_0, win_1, count):\n",
    "\n",
    "        player_responsible = 0\n",
    "\n",
    "        ##### M\n",
    "        n_move = 0\n",
    "        ##### M\n",
    "\n",
    "        for state in states_to_update:\n",
    "            player_responsible = 1 - player_responsible\n",
    "\n",
    "            ##### M\n",
    "            if player_responsible == 1: n_move += 1\n",
    "            amount = win_0 * n_move if player_responsible == 0 else win_1 * n_move\n",
    "            #amount = win_0 if player_responsible == 0 else win_1\n",
    "            ##### M\n",
    "\n",
    "            if state in self.states_dict:\n",
    "                self.states_dict[state][0] += amount\n",
    "                self.states_dict[state][1] += count\n",
    "            else: self.states_dict[state] = [amount, count, []]\n",
    "\n",
    "    ##### A\n",
    "    def evaluate_board(self, board):\n",
    "\n",
    "        player_id = 1 if sum(sum(board < 0)) % 2 == 0 else 0 # (pari -> 1 ha giocato, dispari -> 0 ha giocato), si valuta chi ha appena giocato\n",
    "\n",
    "        bonus = 0\n",
    "        diag_a_player = 0\n",
    "        diag_a_enemy = 0\n",
    "        diag_b_player = 0\n",
    "        diag_b_enemy = 0\n",
    "        for i in range(5):\n",
    "            \n",
    "            line = board[i, :]\n",
    "            bonus += pow(sum(line == player_id), 2) - pow(sum(line == 1 - player_id), 2)\n",
    "            #bonus += sum(line == player_id) - sum(line == 1 - player_id)\n",
    "\n",
    "            line = board[:, i]\n",
    "            bonus += pow(sum(line == player_id), 2) - pow(sum(line == 1 - player_id), 2)\n",
    "            #bonus += sum(line == player_id) - sum(line == 1 - player_id)\n",
    "            \n",
    "            if board[i, i] == player_id: diag_a_player += 1\n",
    "            elif board[i, i] == 1 - player_id: diag_a_enemy += 1\n",
    "            \n",
    "            if board[i, 4-i] == player_id: diag_b_player += 1\n",
    "            elif board[i, 4-i] == 1 - player_id: diag_b_enemy += 1\n",
    "\n",
    "        bonus += pow(diag_a_player, 2) - pow(diag_a_enemy, 2)\n",
    "        #bonus += diag_a_player - diag_a_enemy\n",
    "            \n",
    "        bonus += pow(diag_b_player, 2) - pow(diag_b_enemy, 2)\n",
    "        #bonus += diag_b_player - diag_b_enemy\n",
    "\n",
    "        #bonus += 15 if board[2, 2] == current_player else -16 # the center of the board is used in four winning combination\n",
    "\n",
    "        return bonus / 300\n",
    "    ##### A\n",
    "\n",
    "    def selection_no_R_no_A(self, current_state, path= None):\n",
    "\n",
    "        training = path is not None\n",
    "        #if not training: path = []\n",
    "\n",
    "        if current_state not in self.states_dict:\n",
    "            if training:\n",
    "                print(\"STATE NOT IN STATES_DICT -> IT SHOULDN'T HAPPEN\")\n",
    "                return None\n",
    "            else: return None\n",
    "\n",
    "        parent = self.states_dict[current_state]\n",
    "        parent_count = parent[1]\n",
    "        childrens = parent[2]\n",
    "\n",
    "        if len(childrens) == 0: return None\n",
    "            \n",
    "        has_childs = []\n",
    "        values = []\n",
    "        board = np.array(current_state).reshape(5, 5)\n",
    "        for _, child_state in childrens:\n",
    "            #if child_state not in path:\n",
    "                child = self.states_dict[child_state]\n",
    "                wi = child[0]\n",
    "                ci = child[1]\n",
    "                has_childs.append(len(child[2]) > 0)\n",
    "\n",
    "                if training: values.append((wi / ci) + np.sqrt(self.eps * np.log(parent_count) / ci))\n",
    "                else: values.append(wi / ci)\n",
    "\n",
    "        best_id = np.argmax(values)\n",
    "\n",
    "        if training: return childrens[best_id][1]\n",
    "        else: return childrens[best_id][0]\n",
    "\n",
    "    def selection_R_no_A(self, current_state, path= None):\n",
    "\n",
    "        training = path is not None\n",
    "        #if not training: path = []\n",
    "\n",
    "        if current_state not in self.states_dict:\n",
    "            if training:\n",
    "                print(\"STATE NOT IN STATES_DICT -> IT SHOULDN'T HAPPEN\")\n",
    "                return None\n",
    "            else: return None\n",
    "\n",
    "        parent = self.states_dict[current_state]\n",
    "        parent_count = parent[1]\n",
    "        childrens = parent[2]\n",
    "\n",
    "        if len(childrens) == 0: return None\n",
    "\n",
    "        ##### R\n",
    "        if training:\n",
    "            if np.random.random() < self.eps:\n",
    "                return childrens[np.random.randint(0, len(childrens))][1]\n",
    "        ##### R\n",
    "            \n",
    "        has_childs = []\n",
    "        values = []\n",
    "        board = np.array(current_state).reshape(5, 5)\n",
    "        for _, child_state in childrens:\n",
    "            #if child_state not in path:\n",
    "                child = self.states_dict[child_state]\n",
    "                wi = child[0]\n",
    "                ci = child[1]\n",
    "                has_childs.append(len(child[2]) > 0)\n",
    "\n",
    "                if training: values.append((wi / ci))# + np.sqrt(self.eps * np.log(parent_count) / ci))   ##### not R\n",
    "                else: values.append(wi / ci)\n",
    "\n",
    "        best_id = np.argmax(values)\n",
    "\n",
    "        if training: return childrens[best_id][1]\n",
    "        else: return childrens[best_id][0]\n",
    "\n",
    "    def selection_no_R_A(self, current_state, path= None):\n",
    "\n",
    "        training = path is not None\n",
    "        #if not training: path = []\n",
    "\n",
    "        if current_state not in self.states_dict:\n",
    "            if training:\n",
    "                print(\"STATE NOT IN STATES_DICT -> IT SHOULDN'T HAPPEN\")\n",
    "                return None\n",
    "            else: return None\n",
    "\n",
    "        parent = self.states_dict[current_state]\n",
    "        parent_count = parent[1]\n",
    "        childrens = parent[2]\n",
    "\n",
    "        if len(childrens) == 0: return None\n",
    "            \n",
    "        has_childs = []\n",
    "        values = []\n",
    "        board = np.array(current_state).reshape(5, 5)\n",
    "        for _, child_state in childrens:\n",
    "            #if child_state not in path:\n",
    "                child = self.states_dict[child_state]\n",
    "                wi = child[0]\n",
    "                ci = child[1]\n",
    "                has_childs.append(len(child[2]) > 0)\n",
    "\n",
    "                if training: values.append((wi / ci) + np.sqrt(self.eps * np.log(parent_count) / ci))\n",
    "                else: values.append(wi / ci)\n",
    "\n",
    "                ##### A\n",
    "                values[-1] += self.alpha * self.evaluate_board(np.array(child_state).reshape(5, 5))\n",
    "                ##### A\n",
    "\n",
    "        best_id = np.argmax(values)\n",
    "\n",
    "        if training: return childrens[best_id][1]\n",
    "        else: return childrens[best_id][0]\n",
    "\n",
    "    def selection_R_A(self, current_state, path= None):\n",
    "\n",
    "        training = path is not None\n",
    "        #if not training: path = []\n",
    "\n",
    "        if current_state not in self.states_dict:\n",
    "            if training:\n",
    "                print(\"STATE NOT IN STATES_DICT -> IT SHOULDN'T HAPPEN\")\n",
    "                return None\n",
    "            else: return None\n",
    "\n",
    "        parent = self.states_dict[current_state]\n",
    "        parent_count = parent[1]\n",
    "        childrens = parent[2]\n",
    "\n",
    "        if len(childrens) == 0: return None\n",
    "\n",
    "        ##### R\n",
    "        if training:\n",
    "            if np.random.random() < self.eps:\n",
    "                return childrens[np.random.randint(0, len(childrens))][1]\n",
    "        ##### R\n",
    "            \n",
    "        has_childs = []\n",
    "        values = []\n",
    "        board = np.array(current_state).reshape(5, 5)\n",
    "        for _, child_state in childrens:\n",
    "            #if child_state not in path:\n",
    "                child = self.states_dict[child_state]\n",
    "                wi = child[0]\n",
    "                ci = child[1]\n",
    "                has_childs.append(len(child[2]) > 0)\n",
    "\n",
    "                if training: values.append((wi / ci))# + np.sqrt(self.eps * np.log(parent_count) / ci))   ##### not R\n",
    "                else: values.append(wi / ci)\n",
    "\n",
    "                ##### A\n",
    "                values[-1] += self.alpha * self.evaluate_board(np.array(child_state).reshape(5, 5))\n",
    "                ##### A\n",
    "\n",
    "        best_id = np.argmax(values)\n",
    "\n",
    "        if training: return childrens[best_id][1]\n",
    "        else: return childrens[best_id][0]\n",
    "\n",
    "    def train_init_norm(self):\n",
    "\n",
    "        starting_board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "\n",
    "        win_0, win_1, count = self.simulation(starting_board, 0)\n",
    "\n",
    "        starting_state = tuple(starting_board.flatten())\n",
    "\n",
    "        self.update([starting_state], win_0, win_1, count)\n",
    "\n",
    "    def train_init_moves_simu(self):\n",
    "\n",
    "        starting_board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "\n",
    "        ##### O\n",
    "        path, win_0, win_1, count = self.simulation(starting_board, 0)\n",
    "        #win_0, win_1, count = self.simulation(starting_board, 0)\n",
    "        ##### O\n",
    "\n",
    "        starting_state = tuple(starting_board.flatten())\n",
    "\n",
    "        ##### O\n",
    "        self.update([starting_state] + path, win_0, win_1, count)\n",
    "        #self.update([starting_state], win_0, win_1, count)\n",
    "        ##### O\n",
    "\n",
    "    def train_wrapper_norm(self, training_epochs= 10):\n",
    "\n",
    "        max_depth = 0\n",
    "\n",
    "        for _ in tqdm(range(training_epochs)):\n",
    "        #for _ in range(training_epochs):\n",
    "\n",
    "            \n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            state = tuple(board.flatten())\n",
    "            next_to_move = 0\n",
    "\n",
    "            path = [state]\n",
    "\n",
    "            chosen = self.selection(state, path= path)\n",
    "            while chosen is not None:\n",
    "                path.append(chosen)\n",
    "                next_to_move = 1 - next_to_move\n",
    "                chosen = self.selection(chosen, path= path)\n",
    "            chosen = path[-1]\n",
    "\n",
    "            #print('==================================================')\n",
    "            #print('==================================================')\n",
    "            #print(len(path))\n",
    "            #print(next_to_move)\n",
    "            #print('---------')\n",
    "\n",
    "            if len(path) > max_depth: max_depth = len(path)\n",
    "\n",
    "            board = np.array(chosen).reshape(5, 5)\n",
    "\n",
    "            children = self.expansion(board, next_to_move)\n",
    "\n",
    "            for child in children:\n",
    "                new_state = child[1]\n",
    "                new_board = np.array(new_state).reshape(5, 5)\n",
    "                win_0, win_1, count = self.simulation(new_board, 1 - next_to_move)\n",
    "                new_path = deepcopy(path)\n",
    "                new_path.append(new_state)\n",
    "                self.update(new_path, win_0, win_1, count)\n",
    "                self.states_dict[chosen][2].append(child)\n",
    "\n",
    "        print(f'max depth: {max_depth}')\n",
    "        print(f'states explored: {len(self.states_dict)}')\n",
    "\n",
    "    def train_wrapper_moves_simu(self, training_epochs= 10):\n",
    "\n",
    "        max_depth = 0\n",
    "\n",
    "        for _ in tqdm(range(training_epochs)):\n",
    "        #for _ in range(training_epochs):\n",
    "\n",
    "            \n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            state = tuple(board.flatten())\n",
    "            next_to_move = 0\n",
    "\n",
    "            path = [state]\n",
    "\n",
    "            chosen = self.selection(state, path= path)\n",
    "            while chosen is not None:\n",
    "                path.append(chosen)\n",
    "                next_to_move = 1 - next_to_move\n",
    "                chosen = self.selection(chosen, path= path)\n",
    "            chosen = path[-1]\n",
    "\n",
    "            #print('==================================================')\n",
    "            #print('==================================================')\n",
    "            #print(len(path))\n",
    "            #print(next_to_move)\n",
    "            #print('---------')\n",
    "\n",
    "            if len(path) > max_depth: max_depth = len(path)\n",
    "\n",
    "            board = np.array(chosen).reshape(5, 5)\n",
    "\n",
    "            children = self.expansion(board, next_to_move)\n",
    "\n",
    "            for child in children:\n",
    "                new_state = child[1]\n",
    "                new_board = np.array(new_state).reshape(5, 5)\n",
    "\n",
    "                ##### O\n",
    "                rand_path, win_0, win_1, count = self.simulation(new_board, 1 - next_to_move)\n",
    "                #win_0, win_1, count = self.simulation(new_board, 1 - next_to_move)\n",
    "                ##### O\n",
    "                new_path = deepcopy(path)\n",
    "                new_path.append(new_state)\n",
    "                ##### O\n",
    "                self.update(new_path + rand_path, win_0, win_1, count)\n",
    "                #self.update(new_path, win_0, win_1, count)\n",
    "                ##### O\n",
    "                self.states_dict[chosen][2].append(child)\n",
    "\n",
    "        print(f'max depth: {max_depth}')\n",
    "        print(f'states explored: {len(self.states_dict)}')\n",
    "\n",
    "    def train_wrapper_rand_no_simm(self, n_games= 10):\n",
    "\n",
    "        for _ in tqdm(range(n_games)):\n",
    "\n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            new_state = tuple(board.flatten())\n",
    "            next_to_move = 1\n",
    "\n",
    "            path = []\n",
    "\n",
    "            winner = -1\n",
    "            while winner == -1:\n",
    "\n",
    "                state = new_state\n",
    "\n",
    "                node = self.states_dict[state]\n",
    "                next_to_move = 1 - next_to_move\n",
    "                \n",
    "                from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "\n",
    "                board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "                while not ok:\n",
    "\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "\n",
    "                    board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "\n",
    "                new_state = tuple(board.flatten())\n",
    "\n",
    "                path.append(new_state)\n",
    "\n",
    "                if ((from_pos, move), new_state) not in node[2]: node[2].append(((from_pos, move), new_state))\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            self.update(path, 1 - winner, winner, 1)\n",
    "\n",
    "        print(f'states explored: {len(self.states_dict)}')\n",
    "\n",
    "    def train_wrapper_rand_simm(self, n_games= 10):\n",
    "\n",
    "        for _ in tqdm(range(n_games)):\n",
    "\n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            new_state = tuple(board.flatten())\n",
    "            next_to_move = 1\n",
    "\n",
    "            path = []\n",
    "\n",
    "            winner = -1\n",
    "            while winner == -1:\n",
    "\n",
    "                state = new_state\n",
    "\n",
    "                ######## S\n",
    "                simmetry = check_simmetries(board, self.states_dict)\n",
    "                if simmetry is None: \n",
    "                    self.states_dict[state] = [0, 0, []]\n",
    "                    id_simmetry = None\n",
    "                else: state, id_simmetry = simmetry\n",
    "                #if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\n",
    "                ######## S\n",
    "\n",
    "                node = self.states_dict[state]\n",
    "                next_to_move = 1 - next_to_move\n",
    "                \n",
    "                from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "\n",
    "                ######## S\n",
    "                if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\n",
    "                ######## S\n",
    "\n",
    "                board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "                while not ok:\n",
    "\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "\n",
    "                    ######## S\n",
    "                    if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\n",
    "                    ######## S\n",
    "\n",
    "                    board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "\n",
    "                new_state = tuple(board.flatten())\n",
    "\n",
    "                path.append(new_state)\n",
    "\n",
    "                if ((from_pos, move), new_state) not in node[2]: node[2].append(((from_pos, move), new_state))\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            self.update(path, 1 - winner, winner, 1)\n",
    "\n",
    "        print(f'states explored: {len(self.states_dict)}')\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        self.tot_count += 1\n",
    "\n",
    "        board = game.get_board()\n",
    "        state = tuple(board.flatten())\n",
    "\n",
    "        ######## S\n",
    "        if self.use_simmetries:\n",
    "            simmetry = check_simmetries(board, self.states_dict)\n",
    "            if simmetry is not None: state, id_simmetry = simmetry\n",
    "            else: id_simmetry = None\n",
    "        ######## S\n",
    "\n",
    "        pos_move = self.selection(state)\n",
    "\n",
    "        ######## S\n",
    "        if self.use_simmetries:\n",
    "            if id_simmetry is not None and pos_move is not None: pos_move = inverse_simmetries[id_simmetry](pos_move[0], pos_move[1])\n",
    "        ######## S\n",
    "\n",
    "        rand = False\n",
    "        if pos_move is None: rand = True\n",
    "        elif pos_move == self.last_pos_move:\n",
    "            self.until_move_change -= 1\n",
    "            if self.until_move_change == 0:\n",
    "                rand = True\n",
    "                self.until_move_change = self.base_until_move_change\n",
    "        else: self.last_pos_move = pos_move\n",
    "\n",
    "        if rand:\n",
    "            self.random_count += 1\n",
    "            board = game.get_board()\n",
    "            player_id = game.current_player_idx\n",
    "            from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "            while board[from_pos[1], from_pos[0]] == 1 - player_id: from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "        else: from_pos, move = pos_move\n",
    "        \n",
    "        #print((from_pos, move))\n",
    "        return from_pos, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:08<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 6\n",
      "states explored: 1469700\n",
      "Player won 555 / 1000 as first\n",
      "Player won 496 / 1000 as second\n",
      "player played 4030 non-random moves over 25379 moves as first\n",
      "player played 2792 non-random moves over 24955 moves as second\n"
     ]
    }
   ],
   "source": [
    "#use_simmetries\n",
    "#use_random_games\n",
    "#eps_greedy\n",
    "#eps \n",
    "#add_sim_moves\n",
    "#add_n_moves\n",
    "#add_eval\n",
    "#alpha\n",
    "#simulations_on_new\n",
    "\n",
    "mc = MyPlayer(\n",
    "    use_simmetries= True,\n",
    "    use_random_games= False,\n",
    "    eps_greedy= False,\n",
    "    eps= 0.3,\n",
    "    add_sim_moves= True,\n",
    "    add_n_moves= False,\n",
    "    add_eval= False,\n",
    "    alpha= 1,\n",
    "    simulations_on_new= 1\n",
    ")\n",
    "mc.train_wrapper(1000)\n",
    "\n",
    "ThePlayer = mc\n",
    "\n",
    "wins_first = 0\n",
    "wins_second = 0\n",
    "n_trials = 1000\n",
    "\n",
    "player1 = ThePlayer\n",
    "player2 = RandomPlayer()\n",
    "\n",
    "count_rand_1 = 0\n",
    "count_tot_1 = 0\n",
    "count_rand_2 = 0\n",
    "count_tot_2 = 0\n",
    "\n",
    "for _ in range(n_trials):\n",
    "    \n",
    "    g = Game()\n",
    "    player1.reset_counters()\n",
    "    winner = g.play(player1, player2)\n",
    "    if winner == 0: wins_first += 1\n",
    "    count_rand_1 +=  player1.get_random_count()\n",
    "    count_tot_1 += player1.get_tot_count()\n",
    "\n",
    "    g = Game()\n",
    "    player1.reset_counters()\n",
    "    winner = g.play(player2, player1)\n",
    "    if winner == 1: wins_second += 1\n",
    "    count_rand_2 += player1.get_random_count()\n",
    "    count_tot_2 += player1.get_tot_count()\n",
    "\n",
    "print(f\"Player won {wins_first} / {n_trials} as first\")\n",
    "print(f\"Player won {wins_second} / {n_trials} as second\")\n",
    "print(f'player played {count_tot_1 - count_rand_1} non-random moves over {count_tot_1} moves as first')\n",
    "print(f'player played {count_tot_2 - count_rand_2} non-random moves over {count_tot_2} moves as second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1349\n",
      "Player won 575 / 1000 as first\n",
      "Player won 508 / 1000 as second\n",
      "player played 1232 non-random moves over 23833 moves as first\n",
      "player played 1014 non-random moves over 23386 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1351\n",
      "Player won 561 / 1000 as first\n",
      "Player won 510 / 1000 as second\n",
      "player played 1163 non-random moves over 23941 moves as first\n",
      "player played 1021 non-random moves over 23333 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1346\n",
      "Player won 562 / 1000 as first\n",
      "Player won 470 / 1000 as second\n",
      "player played 1190 non-random moves over 24563 moves as first\n",
      "player played 1019 non-random moves over 23629 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1337\n",
      "Player won 573 / 1000 as first\n",
      "Player won 495 / 1000 as second\n",
      "player played 1211 non-random moves over 24055 moves as first\n",
      "player played 1013 non-random moves over 23452 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 167507\n",
      "Player won 535 / 1000 as first\n",
      "Player won 503 / 1000 as second\n",
      "player played 1220 non-random moves over 24299 moves as first\n",
      "player played 1028 non-random moves over 23757 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 328930\n",
      "Player won 528 / 1000 as first\n",
      "Player won 494 / 1000 as second\n",
      "player played 1192 non-random moves over 23375 moves as first\n",
      "player played 1035 non-random moves over 23550 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 169388\n",
      "Player won 546 / 1000 as first\n",
      "Player won 531 / 1000 as second\n",
      "player played 1222 non-random moves over 24179 moves as first\n",
      "player played 1007 non-random moves over 24443 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 1\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 4\n",
      "states explored: 330350\n",
      "Player won 585 / 1000 as first\n",
      "Player won 498 / 1000 as second\n",
      "player played 1378 non-random moves over 23885 moves as first\n",
      "player played 1059 non-random moves over 23547 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1355\n",
      "Player won 561 / 1000 as first\n",
      "Player won 507 / 1000 as second\n",
      "player played 1166 non-random moves over 24089 moves as first\n",
      "player played 1053 non-random moves over 23508 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1377\n",
      "Player won 556 / 1000 as first\n",
      "Player won 514 / 1000 as second\n",
      "player played 1185 non-random moves over 23741 moves as first\n",
      "player played 1020 non-random moves over 24081 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1326\n",
      "Player won 565 / 1000 as first\n",
      "Player won 494 / 1000 as second\n",
      "player played 1207 non-random moves over 23943 moves as first\n",
      "player played 1014 non-random moves over 23817 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1397\n",
      "Player won 584 / 1000 as first\n",
      "Player won 491 / 1000 as second\n",
      "player played 1161 non-random moves over 24184 moves as first\n",
      "player played 1024 non-random moves over 23661 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 166801\n",
      "Player won 527 / 1000 as first\n",
      "Player won 534 / 1000 as second\n",
      "player played 1161 non-random moves over 23943 moves as first\n",
      "player played 1091 non-random moves over 24130 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 329832\n",
      "Player won 554 / 1000 as first\n",
      "Player won 484 / 1000 as second\n",
      "player played 1168 non-random moves over 23583 moves as first\n",
      "player played 1010 non-random moves over 23516 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 166336\n",
      "Player won 561 / 1000 as first\n",
      "Player won 476 / 1000 as second\n",
      "player played 1188 non-random moves over 23670 moves as first\n",
      "player played 1010 non-random moves over 23221 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 2\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 329062\n",
      "Player won 550 / 1000 as first\n",
      "Player won 493 / 1000 as second\n",
      "player played 1160 non-random moves over 23890 moves as first\n",
      "player played 1026 non-random moves over 23388 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1334\n",
      "Player won 577 / 1000 as first\n",
      "Player won 483 / 1000 as second\n",
      "player played 1130 non-random moves over 23855 moves as first\n",
      "player played 1017 non-random moves over 23175 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1357\n",
      "Player won 569 / 1000 as first\n",
      "Player won 470 / 1000 as second\n",
      "player played 1138 non-random moves over 23470 moves as first\n",
      "player played 1005 non-random moves over 23878 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1332\n",
      "Player won 576 / 1000 as first\n",
      "Player won 538 / 1000 as second\n",
      "player played 1164 non-random moves over 23471 moves as first\n",
      "player played 1043 non-random moves over 23568 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1341\n",
      "Player won 571 / 1000 as first\n",
      "Player won 522 / 1000 as second\n",
      "player played 1150 non-random moves over 24160 moves as first\n",
      "player played 1018 non-random moves over 23415 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 168212\n",
      "Player won 565 / 1000 as first\n",
      "Player won 512 / 1000 as second\n",
      "player played 1140 non-random moves over 23504 moves as first\n",
      "player played 1035 non-random moves over 23378 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 331212\n",
      "Player won 557 / 1000 as first\n",
      "Player won 491 / 1000 as second\n",
      "player played 1149 non-random moves over 23198 moves as first\n",
      "player played 1013 non-random moves over 23623 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 164893\n",
      "Player won 550 / 1000 as first\n",
      "Player won 513 / 1000 as second\n",
      "player played 1159 non-random moves over 23826 moves as first\n",
      "player played 1017 non-random moves over 23682 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 4\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 332750\n",
      "Player won 573 / 1000 as first\n",
      "Player won 497 / 1000 as second\n",
      "player played 1382 non-random moves over 24166 moves as first\n",
      "player played 1042 non-random moves over 23841 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1358\n",
      "Player won 544 / 1000 as first\n",
      "Player won 510 / 1000 as second\n",
      "player played 1178 non-random moves over 24109 moves as first\n",
      "player played 1026 non-random moves over 23497 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1343\n",
      "Player won 567 / 1000 as first\n",
      "Player won 531 / 1000 as second\n",
      "player played 1134 non-random moves over 22993 moves as first\n",
      "player played 1011 non-random moves over 23726 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1341\n",
      "Player won 588 / 1000 as first\n",
      "Player won 505 / 1000 as second\n",
      "player played 1161 non-random moves over 23867 moves as first\n",
      "player played 1007 non-random moves over 23955 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 1371\n",
      "Player won 562 / 1000 as first\n",
      "Player won 512 / 1000 as second\n",
      "player played 1114 non-random moves over 24151 moves as first\n",
      "player played 1031 non-random moves over 23505 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 165300\n",
      "Player won 558 / 1000 as first\n",
      "Player won 515 / 1000 as second\n",
      "player played 1130 non-random moves over 23673 moves as first\n",
      "player played 1022 non-random moves over 23640 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 332535\n",
      "Player won 559 / 1000 as first\n",
      "Player won 535 / 1000 as second\n",
      "player played 1128 non-random moves over 24082 moves as first\n",
      "player played 1019 non-random moves over 23259 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 167915\n",
      "Player won 577 / 1000 as first\n",
      "Player won 478 / 1000 as second\n",
      "player played 1144 non-random moves over 24019 moves as first\n",
      "player played 1012 non-random moves over 23728 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: False\n",
      "eps: 8\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "states explored: 326844\n",
      "Player won 587 / 1000 as first\n",
      "Player won 508 / 1000 as second\n",
      "player played 1479 non-random moves over 24360 moves as first\n",
      "player played 1054 non-random moves over 24274 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 6\n",
      "states explored: 1891\n",
      "Player won 546 / 1000 as first\n",
      "Player won 515 / 1000 as second\n",
      "player played 1517 non-random moves over 24451 moves as first\n",
      "player played 748 non-random moves over 22926 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 6\n",
      "states explored: 1850\n",
      "Player won 547 / 1000 as first\n",
      "Player won 517 / 1000 as second\n",
      "player played 1459 non-random moves over 23798 moves as first\n",
      "player played 690 non-random moves over 23518 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 7\n",
      "states explored: 1809\n",
      "Player won 561 / 1000 as first\n",
      "Player won 506 / 1000 as second\n",
      "player played 1349 non-random moves over 23702 moves as first\n",
      "player played 531 non-random moves over 24066 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: False\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 6\n",
      "states explored: 1849\n",
      "Player won 542 / 1000 as first\n",
      "Player won 501 / 1000 as second\n",
      "player played 1471 non-random moves over 24391 moves as first\n",
      "player played 383 non-random moves over 23240 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 7\n",
      "states explored: 156068\n",
      "Player won 552 / 1000 as first\n",
      "Player won 495 / 1000 as second\n",
      "player played 1217 non-random moves over 23970 moves as first\n",
      "player played 911 non-random moves over 23097 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: True\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 9\n",
      "states explored: 307441\n",
      "Player won 556 / 1000 as first\n",
      "Player won 506 / 1000 as second\n",
      "player played 1349 non-random moves over 24298 moves as first\n",
      "player played 783 non-random moves over 23788 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 6\n",
      "states explored: 160773\n",
      "Player won 555 / 1000 as first\n",
      "Player won 506 / 1000 as second\n",
      "player played 1207 non-random moves over 23747 moves as first\n",
      "player played 605 non-random moves over 23936 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: False\n",
      "eps_greedy: True\n",
      "eps: 0\n",
      "add_sim_moves: True\n",
      "add_n_moves: True\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 5\n",
      "states explored: 313391\n",
      "Player won 555 / 1000 as first\n",
      "Player won 503 / 1000 as second\n",
      "player played 1895 non-random moves over 24281 moves as first\n",
      "player played 551 non-random moves over 23424 moves as second\n",
      "\n",
      "=======================================================================\n",
      "=======================================================================\n",
      "\n",
      "use_simmetries: False\n",
      "use_random_games: True\n",
      "eps_greedy: False\n",
      "eps: 0.25\n",
      "add_sim_moves: False\n",
      "add_n_moves: False\n",
      "add_eval: False\n",
      "alpha: 0\n",
      "simulations_on_new: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 99\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alpha_range:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m simulations_on_new \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m---> 99\u001b[0m         wins, non_rand \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_simmetries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_random_games\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_greedy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_sim_moves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_n_moves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulations_on_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m wins \u001b[38;5;241m>\u001b[39m best_win:\n\u001b[0;32m    102\u001b[0m             best_win \u001b[38;5;241m=\u001b[39m wins\n",
      "Cell \u001b[1;32mIn[37], line 22\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[1;34m(use_simmetries, use_random_games, eps_greedy, eps, add_sim_moves, add_n_moves, add_eval, alpha, simulations_on_new)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimulations_on_new: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimulations_on_new\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m mc \u001b[38;5;241m=\u001b[39m MyPlayer(\n\u001b[0;32m     12\u001b[0m     use_simmetries\u001b[38;5;241m=\u001b[39m use_simmetries,\n\u001b[0;32m     13\u001b[0m     use_random_games\u001b[38;5;241m=\u001b[39m use_random_games,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     simulations_on_new\u001b[38;5;241m=\u001b[39m simulations_on_new\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m ThePlayer \u001b[38;5;241m=\u001b[39m mc\n\u001b[0;32m     26\u001b[0m wins_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[34], line 585\u001b[0m, in \u001b[0;36mMyPlayer.train_wrapper_rand_no_simm\u001b[1;34m(self, n_games)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m winner \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    583\u001b[0m     state \u001b[38;5;241m=\u001b[39m new_state\n\u001b[1;32m--> 585\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    586\u001b[0m     next_to_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m next_to_move\n\u001b[0;32m    588\u001b[0m     from_pos, move \u001b[38;5;241m=\u001b[39m ALL_MOVES[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, N_ALL)]\n",
      "\u001b[1;31mKeyError\u001b[0m: (-1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1)"
     ]
    }
   ],
   "source": [
    "def train_and_test(use_simmetries= False, use_random_games= False, eps_greedy= False, eps= 2, add_sim_moves= False, add_n_moves= False, add_eval= False, alpha= 1, simulations_on_new= 1):\n",
    "    print(f'use_simmetries: {use_simmetries}')\n",
    "    print(f'use_random_games: {use_random_games}')\n",
    "    print(f'eps_greedy: {eps_greedy}')\n",
    "    print(f'eps: {eps}')\n",
    "    print(f'add_sim_moves: {add_sim_moves}')\n",
    "    print(f'add_n_moves: {add_n_moves}')\n",
    "    print(f'add_eval: {add_eval}')\n",
    "    print(f'alpha: {alpha}')\n",
    "    print(f'simulations_on_new: {simulations_on_new}')\n",
    "    mc = MyPlayer(\n",
    "        use_simmetries= use_simmetries,\n",
    "        use_random_games= use_random_games,\n",
    "        eps_greedy= eps_greedy,\n",
    "        eps= eps,\n",
    "        add_sim_moves= add_sim_moves,\n",
    "        add_n_moves= add_n_moves,\n",
    "        add_eval= add_eval,\n",
    "        alpha= alpha,\n",
    "        simulations_on_new= simulations_on_new\n",
    "    )\n",
    "    mc.train_wrapper(100)\n",
    "\n",
    "    ThePlayer = mc\n",
    "\n",
    "    wins_first = 0\n",
    "    wins_second = 0\n",
    "    n_trials = 1000\n",
    "\n",
    "    player1 = ThePlayer\n",
    "    player2 = RandomPlayer()\n",
    "\n",
    "    count_rand_1 = 0\n",
    "    count_tot_1 = 0\n",
    "    count_rand_2 = 0\n",
    "    count_tot_2 = 0\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        \n",
    "        g = Game()\n",
    "        player1.reset_counters()\n",
    "        winner = g.play(player1, player2)\n",
    "        if winner == 0: wins_first += 1\n",
    "        count_rand_1 +=  player1.get_random_count()\n",
    "        count_tot_1 += player1.get_tot_count()\n",
    "\n",
    "        g = Game()\n",
    "        player1.reset_counters()\n",
    "        winner = g.play(player2, player1)\n",
    "        if winner == 1: wins_second += 1\n",
    "        count_rand_2 += player1.get_random_count()\n",
    "        count_tot_2 += player1.get_tot_count()\n",
    "\n",
    "    print(f\"Player won {wins_first} / {n_trials} as first\")\n",
    "    print(f\"Player won {wins_second} / {n_trials} as second\")\n",
    "    print(f'player played {count_tot_1 - count_rand_1} non-random moves over {count_tot_1} moves as first')\n",
    "    print(f'player played {count_tot_2 - count_rand_2} non-random moves over {count_tot_2} moves as second')\n",
    "    print('\\n=======================================================================')\n",
    "    print('=======================================================================\\n')\n",
    "\n",
    "    return wins_first + wins_second, (count_tot_1 - count_rand_1) + (count_tot_2 - count_rand_2)\n",
    "\n",
    "best_no_rand = 0\n",
    "best_no_rand_wins = 0\n",
    "best_conf_no_rand = None\n",
    "best_win = 0\n",
    "best_wins_no_rand = 0\n",
    "best_conf_win = None\n",
    "\n",
    "for use_simmetries in [False, True]:\n",
    "    \n",
    "    for use_random_games in [False, True]:\n",
    "\n",
    "        if use_random_games:\n",
    "            eg_range = [False]\n",
    "            eps_range = [0.25, 0.5, 0.75]\n",
    "            asm_range = [False]\n",
    "        else:\n",
    "            eg_range = [False, True]\n",
    "            eps_range = [1, 2, 4, 8]\n",
    "            asm_range = [False, True]\n",
    "\n",
    "        for eps_greedy in eg_range:\n",
    "            if eps_greedy and not use_random_games: eps_range = [0]\n",
    "\n",
    "            for eps in eps_range:\n",
    "\n",
    "                for add_sim_moves in asm_range:\n",
    "\n",
    "                    for add_n_moves in [False, True]:\n",
    "\n",
    "                        for add_eval in [False]:#, True]:\n",
    "                            alpha_range = [0.25, 1, 4] if add_eval else [0]\n",
    "\n",
    "                            for alpha in alpha_range:\n",
    "\n",
    "                                for simulations_on_new in [1, 2]:\n",
    "\n",
    "                                    wins, non_rand = train_and_test(use_simmetries, use_random_games, eps_greedy, eps, add_sim_moves, add_n_moves, add_eval, alpha, simulations_on_new)\n",
    "\n",
    "                                    if wins > best_win:\n",
    "                                        best_win = wins\n",
    "                                        best_wins_no_rand = non_rand\n",
    "                                        best_conf_win = (use_simmetries, use_random_games, eps_greedy, eps, add_sim_moves, add_n_moves, add_eval, alpha, simulations_on_new)\n",
    "                                    \n",
    "                                    if non_rand > best_no_rand:\n",
    "                                        best_no_rand = non_rand\n",
    "                                        best_no_rand_wins = wins\n",
    "                                        best_conf_no_rand = (use_simmetries, use_random_games, eps_greedy, eps, add_sim_moves, add_n_moves, add_eval, alpha, simulations_on_new)\n",
    "\n",
    "print('best for wins')\n",
    "use_simmetries, use_random_games, eps_greedy, eps, add_sim_moves, add_n_moves, add_eval, alpha, simulations_on_new = best_conf_win\n",
    "print(f'use_simmetries: {use_simmetries}')\n",
    "print(f'use_random_games: {use_random_games}')\n",
    "print(f'eps_greedy: {eps_greedy}')\n",
    "print(f'eps: {eps}')\n",
    "print(f'add_sim_moves: {add_sim_moves}')\n",
    "print(f'add_n_moves: {add_n_moves}')\n",
    "print(f'add_eval: {add_eval}')\n",
    "print(f'alpha: {alpha}')\n",
    "print(f'simulations_on_new: {simulations_on_new}')\n",
    "print('-')\n",
    "print(f'won {best_win} times')\n",
    "print(f'with {best_wins_no_rand} non random moves')\n",
    "\n",
    "print('best for non random moves')\n",
    "use_simmetries, use_random_games, eps_greedy, eps, add_sim_moves, add_n_moves, add_eval, alpha, simulations_on_new = best_conf_no_rand\n",
    "print(f'use_simmetries: {use_simmetries}')\n",
    "print(f'use_random_games: {use_random_games}')\n",
    "print(f'eps_greedy: {eps_greedy}')\n",
    "print(f'eps: {eps}')\n",
    "print(f'add_sim_moves: {add_sim_moves}')\n",
    "print(f'add_n_moves: {add_n_moves}')\n",
    "print(f'add_eval: {add_eval}')\n",
    "print(f'alpha: {alpha}')\n",
    "print(f'simulations_on_new: {simulations_on_new}')\n",
    "print('-')\n",
    "print(f'won {best_no_rand_wins} times')\n",
    "print(f'used {best_no_rand} non random moves')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
