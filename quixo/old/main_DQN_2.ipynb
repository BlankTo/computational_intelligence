{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from game import Game, Move, Player\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy_Game(object):\n",
    "    def __init__(self) -> None:\n",
    "        self._board = np.ones((5, 5), dtype=np.uint8) * -1\n",
    "        self.current_player_idx = 1\n",
    "\n",
    "    def get_board(self): return self._board\n",
    "\n",
    "    def single_move(self, board, from_pos, move, player_id):\n",
    "        self._board = deepcopy(board)\n",
    "        self.current_player_idx = player_id\n",
    "        ok = self.__move(from_pos, move, player_id)\n",
    "        return deepcopy(self._board), ok\n",
    "    \n",
    "    def check_winner_board(self, board):\n",
    "        self._board = board\n",
    "        return self.check_winner()\n",
    "\n",
    "    def check_winner(self) -> int:\n",
    "        for x in range(self._board.shape[0]):\n",
    "            if self._board[x, 0] != -1 and all(self._board[x, :] == self._board[x, 0]): return self._board[x, 0]\n",
    "        for y in range(self._board.shape[1]):\n",
    "            if self._board[0, y] != -1 and all(self._board[:, y] == self._board[0, y]): return self._board[0, y]\n",
    "        if self._board[0, 0] != -1 and all([self._board[x, x] for x in range(self._board.shape[0])] == self._board[0, 0]): return self._board[0, 0]\n",
    "        if self._board[0, -1] != -1 and all([self._board[x, -(x + 1)] for x in range(self._board.shape[0])] == self._board[0, -1]): return self._board[0, -1]\n",
    "        return -1\n",
    "\n",
    "    def __move(self, from_pos: tuple[int, int], slide: Move, player_id: int) -> bool:\n",
    "        if player_id > 2: return False\n",
    "        prev_value = deepcopy(self._board[(from_pos[1], from_pos[0])])\n",
    "        acceptable = self.__take((from_pos[1], from_pos[0]), player_id)\n",
    "        if acceptable:\n",
    "            acceptable = self.__slide((from_pos[1], from_pos[0]), slide)\n",
    "            if not acceptable: self._board[(from_pos[1], from_pos[0])] = deepcopy(prev_value)\n",
    "        return acceptable\n",
    "\n",
    "    def __take(self, from_pos: tuple[int, int], player_id: int) -> bool:\n",
    "        acceptable: bool = ((from_pos[0] == 0 and from_pos[1] < 5) or (from_pos[0] == 4 and from_pos[1] < 5) or (from_pos[1] == 0 and from_pos[0] < 5) or (from_pos[1] == 4 and from_pos[0] < 5)) and (self._board[from_pos] < 0 or self._board[from_pos] == player_id)\n",
    "        if acceptable: self._board[from_pos] = player_id\n",
    "        return acceptable\n",
    "\n",
    "    def __slide(self, from_pos: tuple[int, int], slide: Move) -> bool:\n",
    "        SIDES = [(0, 0), (0, 4), (4, 0), (4, 4)]\n",
    "        if from_pos not in SIDES:\n",
    "            acceptable_top: bool = from_pos[0] == 0 and (slide == Move.BOTTOM or slide == Move.LEFT or slide == Move.RIGHT)\n",
    "            acceptable_bottom: bool = from_pos[0] == 4 and (slide == Move.TOP or slide == Move.LEFT or slide == Move.RIGHT)\n",
    "            acceptable_left: bool = from_pos[1] == 0 and (slide == Move.BOTTOM or slide == Move.TOP or slide == Move.RIGHT)\n",
    "            acceptable_right: bool = from_pos[1] == 4 and (slide == Move.BOTTOM or slide == Move.TOP or slide == Move.LEFT)\n",
    "        else:\n",
    "            acceptable_top: bool = from_pos == (0, 0) and (slide == Move.BOTTOM or slide == Move.RIGHT)\n",
    "            acceptable_left: bool = from_pos == (4, 0) and (slide == Move.TOP or slide == Move.RIGHT)\n",
    "            acceptable_right: bool = from_pos == (0, 4) and (slide == Move.BOTTOM or slide == Move.LEFT)\n",
    "            acceptable_bottom: bool = from_pos == (4, 4) and (slide == Move.TOP or slide == Move.LEFT)\n",
    "        acceptable: bool = acceptable_top or acceptable_bottom or acceptable_left or acceptable_right\n",
    "        if acceptable:\n",
    "            piece = self._board[from_pos]\n",
    "            if slide == Move.LEFT:\n",
    "                for i in range(from_pos[1], 0, -1): self._board[(from_pos[0], i)] = self._board[(from_pos[0], i - 1)]\n",
    "                self._board[(from_pos[0], 0)] = piece\n",
    "            elif slide == Move.RIGHT:\n",
    "                for i in range(from_pos[1], self._board.shape[1] - 1, 1): self._board[(from_pos[0], i)] = self._board[(from_pos[0], i + 1)]\n",
    "                self._board[(from_pos[0], self._board.shape[1] - 1)] = piece\n",
    "            elif slide == Move.TOP:\n",
    "                for i in range(from_pos[0], 0, -1): self._board[(i, from_pos[1])] = self._board[(i - 1, from_pos[1])]\n",
    "                self._board[(0, from_pos[1])] = piece\n",
    "            elif slide == Move.BOTTOM:\n",
    "                for i in range(from_pos[0], self._board.shape[0] - 1, 1): self._board[(i, from_pos[1])] = self._board[(i + 1, from_pos[1])]\n",
    "                self._board[(self._board.shape[0] - 1, from_pos[1])] = piece\n",
    "        return acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "border = []\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i == 0 or i == 4 or j == 0 or j == 4:\n",
    "            border.append((i, j))\n",
    "BORDER = (list(set(border)))\n",
    "print(len(BORDER))\n",
    "\n",
    "def tile_to_moves(tile):\n",
    "    possible_moves = [Move.TOP, Move.BOTTOM, Move.LEFT, Move.RIGHT]\n",
    "        \n",
    "    if tile[0] == 0: possible_moves.remove(Move.LEFT)\n",
    "    if tile[0] == 4: possible_moves.remove(Move.RIGHT)\n",
    "    if tile[1] == 0: possible_moves.remove(Move.TOP)\n",
    "    if tile[1] == 4: possible_moves.remove(Move.BOTTOM)\n",
    "\n",
    "    return possible_moves\n",
    "\n",
    "tile_moves = {tile: tile_to_moves(tile) for tile in BORDER}\n",
    "\n",
    "ALL_MOVES = []\n",
    "for tile in BORDER:\n",
    "    possible_moves = tile_moves[tile]\n",
    "    for move in possible_moves: ALL_MOVES.append((tile, move))\n",
    "N_ALL = len(ALL_MOVES)\n",
    "\n",
    "class RandomPlayer(Player):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        from_pos = random.choice(BORDER)\n",
    "        while game.get_board()[from_pos[1], from_pos[0]] == 1 - game.current_player_idx: from_pos = random.choice(BORDER)\n",
    "\n",
    "        possible_moves = tile_moves[from_pos]\n",
    "        \n",
    "        move = random.choice(possible_moves)\n",
    "\n",
    "        return from_pos, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## state can be represented as two numbers if 0,1 are considered as bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n",
      "[[ 1  1  1  1  1]\n",
      " [-1  1  0  1 -1]\n",
      " [-1  0  0  0  0]\n",
      " [ 1  1 -1  1  0]\n",
      " [ 1  1  0  1  1]]\n",
      "\n",
      "State:\n",
      "19245781287771\n",
      "\n",
      "Board:\n",
      "[[ 1  1  1  1  1]\n",
      " [-1  1  0  1 -1]\n",
      " [-1  0  0  0  0]\n",
      " [ 1  1 -1  1  0]\n",
      " [ 1  1  0  1  1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def state_to_board(state):\n",
    "    binary_string = format(state, '050b')\n",
    "    binary_array = np.array(list(map(int, binary_string))).reshape(2, 5, 5)\n",
    "\n",
    "    board = np.zeros((5, 5), dtype=int)\n",
    "    board[binary_array[0] == 1] = -1\n",
    "    board[binary_array[1] == 1] = 1\n",
    "\n",
    "    return board\n",
    "\n",
    "def board_to_state(board):\n",
    "    binary_array = np.zeros((2, 5, 5), dtype=int)\n",
    "    \n",
    "    binary_array[0][board == -1] = 1\n",
    "    binary_array[1][board == 1] = 1\n",
    "\n",
    "    binary_string = ''.join(map(str, binary_array.flatten()))\n",
    "    return int(binary_string, 2)\n",
    "\n",
    "\n",
    "\n",
    "rand_board = np.random.choice([-1, 0, 1], size=(5, 5), replace=True)\n",
    "print('Board:')\n",
    "print(rand_board)\n",
    "\n",
    "rand_state = board_to_state(rand_board)\n",
    "rand_board = state_to_board(rand_state)\n",
    "\n",
    "print('\\nState:')\n",
    "print(rand_state)\n",
    "print('\\nBoard:')\n",
    "print(state_to_board(rand_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "dict_rot = {\n",
    "    (Move.TOP, 1): Move.LEFT,\n",
    "    (Move.TOP, 2): Move.BOTTOM,\n",
    "    (Move.TOP, 3): Move.RIGHT,\n",
    "    (Move.BOTTOM, 1): Move.RIGHT,\n",
    "    (Move.BOTTOM, 2): Move.TOP,\n",
    "    (Move.BOTTOM, 3): Move.LEFT,\n",
    "    (Move.LEFT, 1): Move.TOP,\n",
    "    (Move.LEFT, 2): Move.RIGHT,\n",
    "    (Move.LEFT, 3): Move.BOTTOM,\n",
    "    (Move.RIGHT, 1): Move.BOTTOM,\n",
    "    (Move.RIGHT, 2): Move.LEFT,\n",
    "    (Move.RIGHT, 3): Move.TOP,\n",
    "}\n",
    "\n",
    "dict_flip = {\n",
    "    Move.TOP: Move.TOP,\n",
    "    Move.BOTTOM: Move.BOTTOM,\n",
    "    Move.LEFT: Move.RIGHT,\n",
    "    Move.RIGHT: Move.LEFT,\n",
    "}\n",
    "\n",
    "#rot_orario: (3, 4) -> (4, 1) -> (1, 0) -> (0, 3) -> (3, 4)\n",
    "#: (xi, yi) -> (yi, 4 - xi)\n",
    "#rot_anti_orario: (3, 4) -> (0, 3) -> (1, 0) -> (4, 1) -> (3, 4)\n",
    "#: (xi, yi) -> (4 - yi, xi)\n",
    "\n",
    "def rot(n_rot):\n",
    "    def rot_n(from_pos, move):\n",
    "        for _ in range(n_rot):\n",
    "            from_pos = 4 - from_pos[1], from_pos[0]\n",
    "        return from_pos, dict_rot[(move, n_rot)]\n",
    "    return rot_n\n",
    "\n",
    "def flip(from_pos, move):\n",
    "    from_pos = 4 - from_pos[0], from_pos[1]\n",
    "    return from_pos, dict_flip[move]\n",
    "\n",
    "def flip_rot(n_rot):\n",
    "    def flip_rot_n(from_pos, move):\n",
    "        from_pos, move = rot(n_rot)(from_pos, move)\n",
    "        return flip(from_pos, move)\n",
    "    return flip_rot_n\n",
    "\n",
    "rot1 = rot(1)\n",
    "rot2 = rot(2)\n",
    "rot3 = rot(3)\n",
    "flip_rot1 = flip_rot(1)\n",
    "flip_rot2 = flip_rot(2)\n",
    "flip_rot3 = flip_rot(3)\n",
    "\n",
    "verse_simmetries = [\n",
    "    rot3,\n",
    "    rot2,\n",
    "    rot1,\n",
    "    flip,\n",
    "    flip_rot3,\n",
    "    flip_rot2,\n",
    "    flip_rot1,\n",
    "]\n",
    "\n",
    "inverse_simmetries = [\n",
    "    rot1,\n",
    "    rot2,\n",
    "    rot3,\n",
    "    flip,\n",
    "    flip_rot1,\n",
    "    flip_rot2,\n",
    "    flip_rot3,\n",
    "]\n",
    "\n",
    "def check_simmetries(board, state_list):\n",
    "\n",
    "    if tuple(board.flatten()) in state_list: return tuple(board.flatten()), None\n",
    "\n",
    "    R1 = np.rot90(board)\n",
    "    if tuple(R1.flatten()) in state_list: return tuple(R1.flatten()), 0\n",
    "\n",
    "    R2 = np.rot90(R1)\n",
    "    if tuple(R2.flatten()) in state_list: return tuple(R2.flatten()), 1\n",
    "\n",
    "    R3 = np.rot90(R2)\n",
    "    if tuple(R3.flatten()) in state_list: return tuple(R3.flatten()), 2\n",
    "    \n",
    "    F = np.fliplr(board)\n",
    "    if tuple(F.flatten()) in state_list: return tuple(F.flatten()), 3\n",
    "    \n",
    "    FR1 = np.rot90(F)\n",
    "    if tuple(FR1.flatten()) in state_list: return tuple(FR1.flatten()), 4\n",
    "    \n",
    "    FR2 = np.rot90(FR1)\n",
    "    if tuple(FR2.flatten()) in state_list: return tuple(FR2.flatten()), 5\n",
    "    \n",
    "    FR3 = np.rot90(FR2)\n",
    "    if tuple(FR3.flatten()) in state_list: return tuple(FR3.flatten()), 6\n",
    "    \n",
    "    return None\n",
    "\n",
    "MOVES_SIMMETRIES = {} #(id_move, id_simmetry) -> id_move\n",
    "\n",
    "for id_move in range(len(ALL_MOVES)):\n",
    "    from_pos, move = ALL_MOVES[id_move]\n",
    "\n",
    "    for id_simmetry in range(len(inverse_simmetries)):\n",
    "\n",
    "        idx = None\n",
    "        for i in range(len(ALL_MOVES)):\n",
    "            if ALL_MOVES[i] == inverse_simmetries[id_simmetry](from_pos, move):\n",
    "                idx = i\n",
    "                break\n",
    "        \n",
    "        MOVES_SIMMETRIES[(id_move, id_simmetry)] = i\n",
    "\n",
    "print(len(MOVES_SIMMETRIES))\n",
    "print(len(ALL_MOVES) * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to discard for the amount of possible states\n",
    "\n",
    "## to change with a check that control if a state already exist, if yes retreive the q-values, if not it creates a random q-value for \n",
    "## each move for that state, if legal\n",
    "\n",
    "\n",
    "#import itertools\n",
    "#from tqdm import tqdm\n",
    "#MATRIX_SIZE = 5\n",
    "#\n",
    "#count_all = 0\n",
    "#for s in itertools.product([-1, 0, 1], repeat= pow(MATRIX_SIZE, 2)): count_all += 1\n",
    "#print(count_all)\n",
    "#print('--------------')\n",
    "#\n",
    "#states_list = []\n",
    "#\n",
    "#for s in tqdm(itertools.product([-1, 0, 1], repeat= pow(MATRIX_SIZE, 2))):\n",
    "#    if check_simmetries(np.array(s).reshape(MATRIX_SIZE, MATRIX_SIZE), states_list) is None:\n",
    "#        states_list.append(tuple(s))\n",
    "#    \n",
    "#    #if count_all % 100 == 0:\n",
    "#    #    print((len(states_list), count_all))\n",
    "#\n",
    "#print(count_all)\n",
    "#print(len(states_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPlayer(Player):\n",
    "    def __init__(self, eps= 2, simulations_on_new= 1, base_until_move_change= 10) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.simulation_on_new = simulations_on_new\n",
    "\n",
    "        self.states_dict = {}\n",
    "\n",
    "        self.dummy = Dummy_Game()\n",
    "\n",
    "        self.train_init()\n",
    "\n",
    "        self.base_until_move_change = base_until_move_change\n",
    "        self.last_pos_move = None\n",
    "        self.until_move_change = self.base_until_move_change\n",
    "        self.n_move_changes = 0\n",
    "\n",
    "        self.tot_count = 0\n",
    "        self.random_count = 0\n",
    "\n",
    "    def get_random_count(self): return self.random_count\n",
    "    def get_tot_count(self): return self.tot_count\n",
    "    def get_n_move_changes(self): return self.n_move_changes\n",
    "    def reset_counters(self):\n",
    "        self.n_move_changes = 0\n",
    "        self.tot_count = 0\n",
    "        self.random_count = 0\n",
    "        self.until_move_change = self.base_until_move_change\n",
    "\n",
    "    def expansion(self, board, next_to_move):\n",
    "\n",
    "        # get legal childrens of a node, child: (move_to_child, child_state)\n",
    "\n",
    "        children = []\n",
    "        for from_pos, move in ALL_MOVES:\n",
    "            new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "            if ok: children.append(((from_pos, move), tuple(new_board.flatten())))\n",
    "\n",
    "        return children\n",
    "    \n",
    "    def simulation(self, base_board, next_to_move):\n",
    "\n",
    "        # random simulation from a certain state to the end, return outcomes\n",
    "\n",
    "        win_0 = 0\n",
    "        win_1 = 0\n",
    "\n",
    "        for _ in range(self.simulation_on_new):\n",
    "\n",
    "            next_to_play = next_to_move\n",
    "            board = deepcopy(base_board)\n",
    "\n",
    "            winner = self.dummy.check_winner_board(board)\n",
    "            while winner == -1:\n",
    "\n",
    "                from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "                while not ok:\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                    new_board, ok = self.dummy.single_move(board, from_pos, move, next_to_play)\n",
    "\n",
    "                board = new_board\n",
    "                next_to_play = 1 - next_to_play\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            if winner == 0: win_0 += 1\n",
    "            else: win_1 += 1\n",
    "        \n",
    "        return win_0, win_1, self.simulation_on_new\n",
    "    \n",
    "    def update(self, states_to_update, win_0, win_1, count):\n",
    "\n",
    "        player_responsible = 0\n",
    "\n",
    "        ##### M\n",
    "        #n_move = 0\n",
    "        ##### M\n",
    "\n",
    "        for state in states_to_update:\n",
    "            player_responsible = 1 - player_responsible\n",
    "\n",
    "            ##### M\n",
    "            #if player_responsible == 1: n_move += 1\n",
    "            #amount = win_0 * n_move if player_responsible == 0 else win_1 * n_move\n",
    "            amount = win_0 if player_responsible == 0 else win_1\n",
    "            ##### M\n",
    "\n",
    "            if state in self.states_dict:\n",
    "                self.states_dict[state][0] += amount\n",
    "                self.states_dict[state][1] += count\n",
    "            else: self.states_dict[state] = [amount, count, []]\n",
    "\n",
    "    def selection(self, current_state, path= None):\n",
    "\n",
    "        training = path is not None\n",
    "        #if not training: path = []\n",
    "\n",
    "        if current_state not in self.states_dict:\n",
    "            if training:\n",
    "                print(\"STATE NOT IN STATES_DICT -> IT SHOULDN'T HAPPEN\")\n",
    "                return None\n",
    "            else: return None\n",
    "\n",
    "        parent = self.states_dict[current_state]\n",
    "        parent_count = parent[1]\n",
    "        childrens = parent[2]\n",
    "\n",
    "        if len(childrens) == 0: return None\n",
    "\n",
    "        if training:\n",
    "            if np.random.random() < self.eps:\n",
    "                return childrens[np.random.randint(0, len(childrens))][1]\n",
    "\n",
    "        has_childs = []\n",
    "        values = []\n",
    "        for _, child_state in childrens:\n",
    "            #if child_state not in path:\n",
    "                child = self.states_dict[child_state]\n",
    "                wi = child[0]\n",
    "                ci = child[1]\n",
    "                has_childs.append(len(child[2]) > 0)\n",
    "\n",
    "                if training: values.append((wi / ci))# + np.sqrt(self.eps * np.log(parent_count) / ci))\n",
    "                else: values.append(wi / ci)\n",
    "\n",
    "        best_id = np.argmax(values)\n",
    "\n",
    "        if training: return childrens[best_id][1]\n",
    "        else: return childrens[best_id][0]\n",
    "\n",
    "    def train_init(self):\n",
    "\n",
    "        starting_board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "\n",
    "        win_0, win_1, count = self.simulation(starting_board, 0)\n",
    "\n",
    "        starting_state = tuple(starting_board.flatten())\n",
    "\n",
    "        self.update([starting_state], win_0, win_1, count)\n",
    "\n",
    "    def train_wrapper(self, n_games= 10):\n",
    "\n",
    "        for _ in tqdm(range(n_games)):\n",
    "\n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            new_state = tuple(board.flatten())\n",
    "            next_to_move = 1\n",
    "\n",
    "            path = []\n",
    "\n",
    "            winner = -1\n",
    "            while winner == -1:\n",
    "\n",
    "                state = new_state\n",
    "\n",
    "                ######## S\n",
    "                simmetry = check_simmetries(board, self.states_dict)\n",
    "                if simmetry is None: \n",
    "                    self.states_dict[state] = [0, 0, []]\n",
    "                    id_simmetry = None\n",
    "                else: state, id_simmetry = simmetry\n",
    "                #if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\n",
    "                ######## S\n",
    "\n",
    "                node = self.states_dict[state]\n",
    "                next_to_move = 1 - next_to_move\n",
    "                \n",
    "                from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "\n",
    "                ######## S\n",
    "                if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\n",
    "                ######## S\n",
    "\n",
    "                board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "                while not ok:\n",
    "\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "\n",
    "                    ######## S\n",
    "                    if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\n",
    "                    ######## S\n",
    "\n",
    "                    board, ok = self.dummy.single_move(board, from_pos, move, next_to_move)\n",
    "\n",
    "                new_state = tuple(board.flatten())\n",
    "\n",
    "                path.append(new_state)\n",
    "\n",
    "                if ((from_pos, move), new_state) not in node[2]: node[2].append(((from_pos, move), new_state))\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            self.update(path, 1 - winner, winner, 1)\n",
    "\n",
    "        print(f'states explored: {len(self.states_dict)}')\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        self.tot_count += 1\n",
    "\n",
    "        board = game.get_board()\n",
    "        state = tuple(board.flatten())\n",
    "\n",
    "        ######## S\n",
    "        simmetry = check_simmetries(board, self.states_dict)\n",
    "        if simmetry is not None: state, id_simmetry = simmetry\n",
    "        else: id_simmetry = None\n",
    "        ######## S\n",
    "\n",
    "        pos_move = self.selection(state)\n",
    "\n",
    "        ######## S\n",
    "        if id_simmetry is not None and pos_move is not None: pos_move = inverse_simmetries[id_simmetry](pos_move[0], pos_move[1])\n",
    "        ######## S\n",
    "\n",
    "        rand = False\n",
    "        if pos_move is None: rand = True\n",
    "        elif pos_move == self.last_pos_move:\n",
    "            self.until_move_change -= 1\n",
    "            if self.until_move_change == 0:\n",
    "                rand = True\n",
    "                self.until_move_change = self.base_until_move_change\n",
    "        else: self.last_pos_move = pos_move\n",
    "\n",
    "        if rand:\n",
    "            self.random_count += 1\n",
    "            board = game.get_board()\n",
    "            player_id = game.current_player_idx\n",
    "            from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "            while board[from_pos[1], from_pos[0]] == 1 - player_id: from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "        else: from_pos, move = pos_move\n",
    "        \n",
    "        #print((from_pos, move))\n",
    "        return from_pos, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent(Player):\n",
    "\n",
    "    def __init__(self, player_id= 0, exploration_factor= 0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.exploration_factor =exploration_factor\n",
    "        self.alpha = 0.5\n",
    "\n",
    "        self.prev_state = tuple([-1 for _ in range(25)])\n",
    "        self.state = None\n",
    "\n",
    "        self.player_id = player_id\n",
    "        self.opponent_id = 1 - player_id\n",
    "\n",
    "        self.dummy = Dummy_Game()\n",
    "\n",
    "        self.values = dict()\n",
    "\n",
    "        self.state_move_to_state = dict()\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        self.state = tuple(game.get_board().flatten())\n",
    "        return self.make_optimal_move(self.state)\n",
    "\n",
    "    def choose_move_train(self, state):\n",
    " \n",
    "        if random.random() < self.exploration_factor: pos_move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "        else: pos_move = self.make_optimal_move(self.state)\n",
    "\n",
    "        return pos_move\n",
    "\n",
    "    def make_move_and_learn(self, state):\n",
    "\n",
    "        self.state = state\n",
    "\n",
    "        self.learn_state(state)\n",
    "\n",
    "        return self.choose_move_train(state)\n",
    "\n",
    "    def make_optimal_move(self, state):\n",
    "\n",
    "        temp_pos_move_list = []\n",
    "        v = -float('Inf')\n",
    "\n",
    "        board = np.array(state).reshape(5, 5)\n",
    "        state = tuple(board.flatten())\n",
    "\n",
    "        for from_pos, move in ALL_MOVES:\n",
    "\n",
    "            v_temp = []\n",
    "\n",
    "            ###\n",
    "            if (state, from_pos, move) in self.state_move_to_state:\n",
    "                temp_board = self.state_move_to_state[(state, from_pos, move)]\n",
    "                ok = True\n",
    "            else:\n",
    "                temp_board, ok = self.dummy.single_move(board, from_pos, move, self.player_id)\n",
    "                self.state_move_to_state[(state, from_pos, move)] = temp_board\n",
    "            #temp_board, ok = self.dummy.single_move(board, from_pos, move, self.player_id)\n",
    "            ###\n",
    "            if ok:\n",
    "\n",
    "                temp_state = tuple(temp_board.flatten())\n",
    "\n",
    "                for from_pos_op, move_op in ALL_MOVES:\n",
    "\n",
    "                    ###\n",
    "                    if (temp_state, from_pos_op, move_op) in self.state_move_to_state:\n",
    "                        temp_board_op = self.state_move_to_state[(temp_state, from_pos_op, move_op)]\n",
    "                        ok = True\n",
    "                    else:\n",
    "                        temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\n",
    "                        self.state_move_to_state[(temp_state, from_pos_op, move_op)] = temp_board_op\n",
    "                    #temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\n",
    "                    ###\n",
    "                    if ok:\n",
    "\n",
    "                        temp_state_op = tuple(temp_board_op.flatten())\n",
    "\n",
    "                        if temp_state_op in self.values: v_temp.append(self.values[temp_state_op])\n",
    "\n",
    "                if len(v_temp) != 0: v_temp = np.min(v_temp)\n",
    "                else: v_temp = 1 # to encourage exploration\n",
    "\n",
    "                if v_temp > v:\n",
    "                    temp_pos_move_list = [(from_pos, move)]\n",
    "                    v = v_temp\n",
    "                elif v_temp == v:\n",
    "                    temp_pos_move_list.append((from_pos, move))\n",
    "\n",
    "        try:\n",
    "            new_state = random.choice(temp_pos_move_list)\n",
    "        except ValueError:\n",
    "            print('temp state:', temp_pos_move_list)\n",
    "            raise Exception('temp state empty')\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def reward(self, winner):\n",
    "        if winner == self.player_id:\n",
    "            R = 1\n",
    "        elif winner == -1:\n",
    "            R = 0\n",
    "        else:\n",
    "            R = -1\n",
    "        return R\n",
    "    \n",
    "    def learn_state(self, state):\n",
    "\n",
    "        if self.player_id in state:\n",
    "            if self.prev_state in self.values.keys(): v_s = self.values[self.prev_state]\n",
    "            else: v_s = int(0)\n",
    "\n",
    "            winner = self.dummy.check_winner_board(np.array(state).reshape(5, 5))\n",
    "            R = self.reward(winner)\n",
    "\n",
    "            if self.state in self.values.keys() and winner == -1: v_s_tag = self.values[state] # anche senza .keys() ?\n",
    "            else: v_s_tag = int(0)\n",
    "\n",
    "            self.values[self.prev_state] = v_s + self.alpha*(R + v_s_tag - v_s)\n",
    "\n",
    "        self.prev_state = state\n",
    "\n",
    "    def train(self, n_games= 10000):\n",
    "\n",
    "        for _ in tqdm(range(n_games)):\n",
    "\n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            state = tuple(board.flatten())\n",
    "\n",
    "            winner = -1\n",
    "            while winner == -1:\n",
    "\n",
    "                ######## S\n",
    "                #simmetry = check_simmetries(board, self.states_dict)\n",
    "                #if simmetry is None: \n",
    "                #    self.states_dict[state] = [0, 0, []]\n",
    "                #    id_simmetry = None\n",
    "                #else: state, id_simmetry = simmetry\n",
    "                #if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\n",
    "                ######## S\n",
    "                \n",
    "                from_pos, move = self.make_move_and_learn(state)\n",
    "\n",
    "                ######## S\n",
    "                #if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\n",
    "                ######## S\n",
    "\n",
    "                board, ok = self.dummy.single_move(board, from_pos, move, 0)\n",
    "\n",
    "                state = tuple(board.flatten())\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "                if winner == -1:\n",
    "\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                    board, ok = self.dummy.single_move(board, from_pos, move, 1)\n",
    "                    while not ok:\n",
    "                        from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                        board, ok = self.dummy.single_move(board, from_pos, move, 1)\n",
    "\n",
    "                    state = tuple(board.flatten())\n",
    "\n",
    "                    winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            self.learn_state(state)\n",
    "            #self.learn_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 138/1000 [00:37<03:54,  3.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ThePlayer \u001b[38;5;241m=\u001b[39m QAgent(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mThePlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      6\u001b[0m player1 \u001b[38;5;241m=\u001b[39m ThePlayer\n",
      "Cell \u001b[1;32mIn[37], line 144\u001b[0m, in \u001b[0;36mQAgent.train\u001b[1;34m(self, n_games)\u001b[0m\n\u001b[0;32m    132\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m winner \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m#if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     from_pos, move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_move_and_learn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m#if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     board, ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdummy\u001b[38;5;241m.\u001b[39msingle_move(board, from_pos, move, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[37], line 39\u001b[0m, in \u001b[0;36mQAgent.make_move_and_learn\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_state(state)\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_move_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 29\u001b[0m, in \u001b[0;36mQAgent.choose_move_train\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoose_move_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_factor: pos_move \u001b[38;5;241m=\u001b[39m ALL_MOVES[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, N_ALL)]\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: pos_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_optimal_move\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pos_move\n",
      "Cell \u001b[1;32mIn[37], line 79\u001b[0m, in \u001b[0;36mQAgent.make_optimal_move\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m#temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[1;32m---> 79\u001b[0m         temp_state_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mtemp_board_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m temp_state_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues: v_temp\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[temp_state_op])\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v_temp) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m: v_temp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(v_temp)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ThePlayer = QAgent(0, 0.3)\n",
    "ThePlayer.train(1000)\n",
    "\n",
    "#\n",
    "\n",
    "player1 = ThePlayer\n",
    "player2 = RandomPlayer()\n",
    "\n",
    "n_trials = 100\n",
    "wins_first = 0\n",
    "\n",
    "for _ in tqdm(range(n_trials)):\n",
    "    \n",
    "    g = Game()\n",
    "    winner = g.play(player1, player2)\n",
    "    if winner == 0: wins_first += 1\n",
    "\n",
    "print(f\"Player won {wins_first} / {n_trials} as first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as Kl\n",
    "import keras.models as Km\n",
    "\n",
    "class DeepQAgent(Player):\n",
    "\n",
    "    def __init__(self, player_id= 0, exploration_factor= 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        print('init')\n",
    "\n",
    "        self.exploration_factor = 1\n",
    "        self.until_reduction = 50\n",
    "        self.exploration_factor_after = exploration_factor\n",
    "        self.alpha = 0.5\n",
    "\n",
    "        self.prev_state = tuple([-1 for _ in range(25)])\n",
    "        self.state = None\n",
    "\n",
    "        self.player_id = player_id\n",
    "        self.opponent_id = 1 - player_id\n",
    "\n",
    "        self.dummy = Dummy_Game()\n",
    "\n",
    "        self.values = dict()\n",
    "\n",
    "        self.state_move_to_state = dict()\n",
    "\n",
    "        self.value_model = self.create_model()\n",
    "\n",
    "        self.until_change_move = 5\n",
    "        self.last_move = None\n",
    "        self.last_state = None\n",
    "\n",
    "        self.memory = []\n",
    "        self.memory_empty = []\n",
    "        self.memory_win = []\n",
    "        self.memory_lose = []\n",
    "        self.batch_size = 10\n",
    "\n",
    "        print('init done')\n",
    "\n",
    "    def create_model(self): #########################################################################################################\n",
    "        \n",
    "        model = Km.Sequential()\n",
    "        model.add(Kl.Dense(75, activation='relu', input_dim= 25))\n",
    "        model.add(Kl.Dense(44, activation='relu'))\n",
    "        model.add(Kl.Dense(1, activation='linear'))\n",
    "        model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def choose_move_train(self, state):\n",
    " \n",
    "        if random.random() < self.exploration_factor:\n",
    "            #pos_move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "            board = np.array(state).reshape(5, 5)\n",
    "            ok_moves = []\n",
    "            for from_pos, move in ALL_MOVES:\n",
    "                if board[from_pos[1], from_pos[0]] != 1 - self.player_id: ok_moves.append((from_pos, move))\n",
    "            pos_move = ok_moves[np.random.randint(0, len(ok_moves))]\n",
    "        else: pos_move = self.make_optimal_move(self.state)\n",
    "\n",
    "        return pos_move\n",
    "\n",
    "    def make_move_and_learn(self, state):\n",
    "\n",
    "        self.state = state\n",
    "\n",
    "        self.learn_state(state)\n",
    "\n",
    "        return self.choose_move_train(state)\n",
    "    \n",
    "    def make_optimal_move(self, state):\n",
    "\n",
    "        temp_pos_move_list = []\n",
    "        v = -float('Inf')\n",
    "\n",
    "        board = np.array(state).reshape(5, 5)\n",
    "        state = tuple(board.flatten())\n",
    "\n",
    "        temp_states = []\n",
    "        pos_moves = []\n",
    "        counts = []\n",
    "\n",
    "        for from_pos, move in ALL_MOVES:\n",
    "\n",
    "            v_temp = []\n",
    "\n",
    "            ###\n",
    "            if (state, from_pos, move) in self.state_move_to_state:\n",
    "                temp_board = self.state_move_to_state[(state, from_pos, move)]\n",
    "                ok = True\n",
    "            else:\n",
    "                temp_board, ok = self.dummy.single_move(board, from_pos, move, self.player_id)\n",
    "                if ok: self.state_move_to_state[(state, from_pos, move)] = temp_board\n",
    "            #temp_board, ok = self.dummy.single_move(board, from_pos, move, self.player_id)\n",
    "            ###\n",
    "            if ok:\n",
    "\n",
    "                temp_state = tuple(temp_board.flatten())\n",
    "\n",
    "                count = 0\n",
    "                pos_moves.append((from_pos, move))\n",
    "\n",
    "                for from_pos_op, move_op in ALL_MOVES:\n",
    "                    \n",
    "                    #print(count)\n",
    "\n",
    "                    ###\n",
    "                    if (temp_state, from_pos_op, move_op) in self.state_move_to_state:\n",
    "                        temp_board_op = self.state_move_to_state[(temp_state, from_pos_op, move_op)]\n",
    "                        ok = True\n",
    "                    else:\n",
    "                        temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\n",
    "                        if ok: self.state_move_to_state[(temp_state, from_pos_op, move_op)] = temp_board_op\n",
    "                        \n",
    "                    #temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\n",
    "                    ###\n",
    "                    if ok:\n",
    "\n",
    "                        temp_states.append(temp_board_op.reshape(25,))\n",
    "                        count += 1\n",
    "                \n",
    "                counts.append(count)\n",
    "\n",
    "        values = self.calc_value(np.array(temp_states).reshape(-1, 25))\n",
    "\n",
    "\n",
    "        ###################\n",
    "        count = 0\n",
    "        max_v = -9999\n",
    "        for i in range(len(pos_moves)):\n",
    "            pos_move = pos_moves[i]\n",
    "            v_opp = []\n",
    "            for _ in range(counts[i]):\n",
    "                v = values[count]\n",
    "                count += 1\n",
    "\n",
    "                v_opp.append(v)\n",
    "\n",
    "            pos_move_v = min(v_opp)\n",
    "\n",
    "            if pos_move_v > max_v:\n",
    "                temp_pos_move_list = [pos_move]\n",
    "                max_v = pos_move_v\n",
    "            elif pos_move_v == max_v: temp_pos_move_list.append(pos_move)\n",
    "            #elif pos_move_v > max_v - 1e-4: temp_pos_move_list.append(pos_move) ################################################################\n",
    "\n",
    "        #print(f'max_v: {max_v}')\n",
    "\n",
    "#        count = 0\n",
    "#        for i in range(len(pos_moves)):\n",
    "#            pos_move = pos_moves[i]\n",
    "#            for _ in range(counts[i]):\n",
    "#                v_temp = values[count]\n",
    "#                count += 1\n",
    "#\n",
    "#                if v_temp > v:\n",
    "#                    temp_pos_move_list = [pos_move]\n",
    "#                    v = v_temp\n",
    "#                elif v_temp == v: temp_pos_move_list.append(pos_move)\n",
    "\n",
    "        ####################\n",
    "\n",
    "        new_state = random.choice(temp_pos_move_list)\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def reward(self, winner):\n",
    "        if winner == self.player_id:\n",
    "            R = 1\n",
    "        elif winner == -1:\n",
    "            R = 0\n",
    "        else:\n",
    "            R = -1\n",
    "        return R\n",
    "\n",
    "    def learn_state(self, state):\n",
    "\n",
    "        #########################################################################################################################\n",
    "\n",
    "        self.calc_target(state)\n",
    "\n",
    "        self.train_model(10)\n",
    "        \n",
    "        #\n",
    "        \n",
    "#        winner = self.dummy.check_winner_board(np.array(state).reshape(5, 5))\n",
    "#        \n",
    "#        target = self.calc_target(state, winner)\n",
    "#\n",
    "#        self.train_model(target, 10)\n",
    "\n",
    "        #########################################################################################################################\n",
    "\n",
    "        self.prev_state = state\n",
    "\n",
    "    def calc_value(self, state_array):\n",
    "        return self.value_model.predict(state_array, verbose= 0)\n",
    "\n",
    "        #########################################################################################################################\n",
    "\n",
    "    def calc_target(self, state):\n",
    "\n",
    "        winner = self.dummy.check_winner_board(np.array(state).reshape(5, 5))\n",
    "\n",
    "        #\n",
    "    \n",
    "#    def calc_target(self, state, winner):\n",
    "\n",
    "        #########################################################################################################################\n",
    "\n",
    "        if self.player_id in state:\n",
    "\n",
    "            v_s = self.calc_value(np.array(self.prev_state).reshape(1, 25))\n",
    "\n",
    "            R = self.reward(winner)\n",
    "\n",
    "            #R = self.reward_2(winner, self.prev_state, state) # con evaluate board current - evaluate board pre scalate di 300\n",
    "\n",
    "            if winner == -1: v_s_tag = self.calc_value(np.array(state).reshape(1, 25))\n",
    "            else: v_s_tag = 0\n",
    "\n",
    "        #########################################################################################################################\n",
    "\n",
    "            target = v_s + self.alpha * (R + v_s_tag - v_s)\n",
    "\n",
    "            self.memory.append((self.prev_state, target))\n",
    "            if len(self.memory) > self.batch_size * 10: self.memory = self.memory[1:]\n",
    "\n",
    "            if R == 0:\n",
    "                self.memory_empty.append((self.prev_state, target))\n",
    "                if len(self.memory_empty) > self.batch_size * 10: self.memory_empty = self.memory_empty[1:]\n",
    "            elif R > 0:\n",
    "                self.memory_win.append((self.prev_state, target))\n",
    "                if len(self.memory_win) > self.batch_size * 10: self.memory_win = self.memory_win[1:]\n",
    "            else:\n",
    "                self.memory_lose.append((self.prev_state, target))\n",
    "                if len(self.memory_lose) > self.batch_size * 10: self.memory_lose = self.memory_lose[1:]\n",
    "\n",
    "            #print('-')\n",
    "            #print(len(self.memory_empty))\n",
    "            #print(len(self.memory_win))\n",
    "            #print(len(self.memory_lose))\n",
    "            #print('-')\n",
    "\n",
    "            #\n",
    "\n",
    "#            target = np.array(v_s + self.alpha * (R + v_s_tag - v_s))\n",
    "#\n",
    "#            return target\n",
    "        \n",
    "        #########################################################################################################################\n",
    "            \n",
    "        #########################################################################################################################\n",
    "\n",
    "    def train_model(self, epochs= 10):\n",
    "\n",
    "        ## single batch per epoch or multiple patches per epoch ()\n",
    "\n",
    "        #len_m = len(self.memory)\n",
    "        len_e = len(self.memory_empty)\n",
    "        len_w = len(self.memory_win)\n",
    "        len_l = len(self.memory_lose)\n",
    "\n",
    "        #if len_m > self.batch_size:\n",
    "        if len_e > self.batch_size and len_w > self.batch_size and len_l > self.batch_size:\n",
    "            \n",
    "            X_train = []\n",
    "            Y_train = []\n",
    "\n",
    "            if self.until_reduction > 0:\n",
    "                self.until_reduction -= 1\n",
    "                if self.until_reduction == 0: self.exploration_factor = self.exploration_factor_after\n",
    "\n",
    "            # memory\n",
    "            #idx_rand = np.random.choice(range(len_m), size= (self.batch_size,), replace= False)\n",
    "            #xy = [self.memory[i] for i in idx_rand]\n",
    "            #for x, y in xy:\n",
    "            #    X_train.append(np.array(x))\n",
    "            #    Y_train.append(y)\n",
    "        \n",
    "            # occorre giocare random puro all'inizio, altrimenti win è rara e non riempe il buffer\n",
    "            idx_rand = np.random.choice(range(len_e), size= (self.batch_size,), replace= False)\n",
    "            empty = [self.memory_empty[i] for i in idx_rand]\n",
    "            idx_rand = np.random.choice(range(len_w), size= (self.batch_size,), replace= False)\n",
    "            win = [self.memory_win[i] for i in idx_rand]\n",
    "            idx_rand = np.random.choice(range(len_l), size= (self.batch_size,), replace= False)\n",
    "            lose = [self.memory_lose[i] for i in idx_rand]\n",
    "            \n",
    "            for e, w, l in zip(empty, win, lose):\n",
    "                X_train.append(np.array(e[0]))\n",
    "                X_train.append(np.array(w[0]))\n",
    "                X_train.append(np.array(l[0]))\n",
    "                Y_train.append(e[1])\n",
    "                Y_train.append(w[1])\n",
    "                Y_train.append(l[1])\n",
    "            \n",
    "            #print(f'exploration factor: {self.exploration_factor}')\n",
    "            X_train = np.array(X_train)\n",
    "            #print(f'X_train shape: {X_train.shape}')\n",
    "            Y_train = np.array(Y_train)\n",
    "            #print(f'Y_train shape: {Y_train.shape}')\n",
    "            \n",
    "            self.value_model.fit(X_train, Y_train, batch_size= self.batch_size * 3, epochs=epochs, verbose=0)\n",
    "\n",
    "        #if len(self.memory_empty) > 2 and len(self.memory_win) > 2 and len(self.memory_lose) > 2:\n",
    "        #    \n",
    "        #    X_train = []\n",
    "        #    Y_train = []\n",
    "        #\n",
    "        #    for _ in range(self.batch_size):\n",
    "        #        choice = np.random.randint(-1, 2)\n",
    "        #        if choice < 0:\n",
    "        #            X_train.append(random.choice(self.memory_empty)[0])\n",
    "        #            Y_train.append(random.choice(self.memory_empty)[1])\n",
    "        #        elif choice == 0:\n",
    "        #            X_train.append(random.choice(self.memory_win)[0])\n",
    "        #            Y_train.append(random.choice(self.memory_win)[1])\n",
    "        #        else:\n",
    "        #            X_train.append(random.choice(self.memory_lose)[0])\n",
    "        #            Y_train.append(random.choice(self.memory_lose)[1])\n",
    "        #\n",
    "        #    X_train = np.array(X_train)\n",
    "        #    print(f'X_train shape: {X_train.shape}')\n",
    "        #    Y_train = np.array(Y_train)\n",
    "        #    print(f'Y_train shape: {Y_train.shape}')\n",
    "        #\n",
    "        #    self.value_model.fit(X_train, Y_train, batch_size= self.batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "        #\n",
    "\n",
    "#    def train_model(self, target, epochs):\n",
    "#\n",
    "#        X_train = np.array(self.prev_state).reshape(1, 25)\n",
    "#\n",
    "#        if target is not None: self.value_model.fit(X_train, target, epochs=epochs, verbose=0)\n",
    "\n",
    "        #########################################################################################################################\n",
    "\n",
    "    def train(self, n_games= 1000):\n",
    "\n",
    "        for _ in tqdm(range(n_games)):\n",
    "\n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            state = tuple(board.flatten())\n",
    "\n",
    "            winner = -1\n",
    "            while winner == -1:\n",
    "\n",
    "                #print('move')\n",
    "\n",
    "                ######## S\n",
    "                #simmetry = check_simmetries(board, self.states_dict)\n",
    "                #if simmetry is None: \n",
    "                #    self.states_dict[state] = [0, 0, []]\n",
    "                #    id_simmetry = None\n",
    "                #else: state, id_simmetry = simmetry\n",
    "                #if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\n",
    "                ######## S\n",
    "                \n",
    "                from_pos, move = self.make_move_and_learn(state)\n",
    "\n",
    "                ######## S\n",
    "                #if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\n",
    "                ######## S\n",
    "\n",
    "                board, ok = self.dummy.single_move(board, from_pos, move, 0)\n",
    "\n",
    "                state = tuple(board.flatten())\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "                if winner == -1:\n",
    "\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                    board, ok = self.dummy.single_move(board, from_pos, move, 1)\n",
    "                    while not ok:\n",
    "                        from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                        board, ok = self.dummy.single_move(board, from_pos, move, 1)\n",
    "\n",
    "                    state = tuple(board.flatten())\n",
    "\n",
    "                    winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            self.learn_state(state)\n",
    "            #self.learn_state(state)\n",
    "\n",
    "    \n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        board = game.get_board()\n",
    "        self.state = tuple(board.flatten())\n",
    "        pos_move = self.make_optimal_move(self.state)\n",
    "\n",
    "        if self.last_state == self.state and pos_move == self.last_move:\n",
    "            self.until_change_move -= 1\n",
    "            if self.until_change_move == 0:\n",
    "                #print('change')\n",
    "                ok_moves = []\n",
    "                for from_pos, move in ALL_MOVES:\n",
    "                    if board[from_pos[1], from_pos[0]] != 1 - self.player_id: ok_moves.append((from_pos, move))\n",
    "                pos_move = ok_moves[np.random.randint(0, len(ok_moves))]\n",
    "                self.until_change_move = 2\n",
    "        else: self.until_change_move = 2\n",
    "\n",
    "        self.last_state = self.state\n",
    "        self.last_move = pos_move\n",
    "\n",
    "        #print(board)\n",
    "        #print(pos_move)\n",
    "\n",
    "        return pos_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 75)                1950      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 44)                3344      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,339\n",
      "Trainable params: 5,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "init done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 533/10000 [42:03<12:27:01,  4.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ThePlayer \u001b[38;5;241m=\u001b[39m DeepQAgent(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mThePlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#to_do:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#- check single memory\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#- more dense\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#- conv\u001b[39;00m\n\u001b[0;32m     13\u001b[0m player1 \u001b[38;5;241m=\u001b[39m ThePlayer\n",
      "Cell \u001b[1;32mIn[12], line 363\u001b[0m, in \u001b[0;36mDeepQAgent.train\u001b[1;34m(self, n_games)\u001b[0m\n\u001b[0;32m    349\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m winner \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m     \u001b[38;5;66;03m#print('move')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m#if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     from_pos, move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_move_and_learn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;66;03m#if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\u001b[39;00m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     board, ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdummy\u001b[38;5;241m.\u001b[39msingle_move(board, from_pos, move, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 70\u001b[0m, in \u001b[0;36mDeepQAgent.make_move_and_learn\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_move_and_learn\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoose_move_train(state)\n",
      "Cell \u001b[1;32mIn[12], line 185\u001b[0m, in \u001b[0;36mDeepQAgent.learn_state\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m         \u001b[38;5;66;03m#########################################################################################################################\u001b[39;00m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_target(state)\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    188\u001b[0m         \n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m#        winner = self.dummy.check_winner_board(np.array(state).reshape(5, 5))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m         \u001b[38;5;66;03m#########################################################################################################################\u001b[39;00m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_state \u001b[38;5;241m=\u001b[39m state\n",
      "Cell \u001b[1;32mIn[12], line 306\u001b[0m, in \u001b[0;36mDeepQAgent.train_model\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    303\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Y_train)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m#print(f'Y_train shape: {Y_train.shape}')\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py:1672\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1665\u001b[0m (\n\u001b[0;32m   1666\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_epoch,\n\u001b[0;32m   1667\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step,\n\u001b[0;32m   1668\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_counters_from_ckpt(\n\u001b[0;32m   1669\u001b[0m     steps_per_epoch_inferred, initial_epoch\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():\n\u001b[0;32m   1673\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   1674\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1305\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1305\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:505\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    504\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:713\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    709\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    711\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    712\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 713\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:752\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    749\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    750\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    751\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 752\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3439\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3438\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3439\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3440\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3442\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ThePlayer = DeepQAgent(0)\n",
    "ThePlayer.train(1000)\n",
    "\n",
    "#\n",
    "#to_do:\n",
    "#- check single memory\n",
    "#- reward_2\n",
    "#- trainare per un po\n",
    "#- more dense\n",
    "#- conv\n",
    "\n",
    "\n",
    "player1 = ThePlayer\n",
    "player2 = RandomPlayer()\n",
    "\n",
    "n_trials = 1000\n",
    "wins_first = 0\n",
    "\n",
    "for _ in tqdm(range(n_trials)):\n",
    "    \n",
    "    g = Game()\n",
    "    winner = g.play(player1, player2)\n",
    "    if winner == 0: wins_first += 1\n",
    "\n",
    "print(f\"Player won {wins_first} / {n_trials} as first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1_old = ThePlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:51<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player won 57 / 100 as first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "player2 = RandomPlayer()\n",
    "\n",
    "n_trials = 100\n",
    "wins_first = 0\n",
    "\n",
    "for _ in tqdm(range(n_trials)):\n",
    "    \n",
    "    g = Game()\n",
    "    winner = g.play(player1_old, player2)\n",
    "    if winner == 0: wins_first += 1\n",
    "\n",
    "print(f\"Player won {wins_first} / {n_trials} as first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as Kl\n",
    "import keras.models as Km\n",
    "\n",
    "class DeepQAgent(Player):\n",
    "\n",
    "    def __init__(self, player_id= 0, exploration_factor= 0):\n",
    "        super().__init__()\n",
    "\n",
    "        print('init')\n",
    "\n",
    "        self.exploration_factor =exploration_factor\n",
    "        self.alpha = 0.5\n",
    "\n",
    "        self.prev_state = tuple([-1 for _ in range(25)])\n",
    "        self.state = None\n",
    "\n",
    "        self.player_id = player_id\n",
    "        self.opponent_id = 1 - player_id\n",
    "\n",
    "        self.dummy = Dummy_Game()\n",
    "\n",
    "        self.values = dict()\n",
    "\n",
    "        self.state_move_to_state = dict()\n",
    "\n",
    "        self.value_model = self.create_model()\n",
    "\n",
    "        print('init done')\n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        model = Km.Sequential()\n",
    "        model.add(Kl.Dense(2, activation='relu', input_dim= 25))\n",
    "        model.add(Kl.Dense(2, activation='relu'))\n",
    "        model.add(Kl.Dense(1, activation='linear'))\n",
    "        model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def make_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        self.state = tuple(game.get_board().flatten())\n",
    "        return self.make_optimal_move(self.state)\n",
    "\n",
    "    def choose_move_train(self, state):\n",
    " \n",
    "        if random.random() < self.exploration_factor: pos_move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "        else: pos_move = self.make_optimal_move(self.state)\n",
    "\n",
    "        return pos_move\n",
    "\n",
    "    def make_move_and_learn(self, state):\n",
    "\n",
    "        self.state = state\n",
    "\n",
    "        self.learn_state(state)\n",
    "\n",
    "        return self.choose_move_train(state)\n",
    "\n",
    "    def make_optimal_move(self, state):\n",
    "\n",
    "        temp_pos_move_list = []\n",
    "        v = -float('Inf')\n",
    "\n",
    "        board = np.array(state).reshape(5, 5)\n",
    "        state = tuple(board.flatten())\n",
    "\n",
    "        temp_states = []\n",
    "        pos_moves = []\n",
    "\n",
    "        for from_pos, move in ALL_MOVES:\n",
    "\n",
    "            v_temp = []\n",
    "\n",
    "            ###\n",
    "            if (state, from_pos, move) in self.state_move_to_state:\n",
    "                temp_board = self.state_move_to_state[(state, from_pos, move)]\n",
    "                ok = True\n",
    "            else:\n",
    "                temp_board, ok = self.dummy.single_move(board, from_pos, move, self.player_id)\n",
    "                self.state_move_to_state[(state, from_pos, move)] = temp_board\n",
    "            #temp_board, ok = self.dummy.single_move(board, from_pos, move, self.player_id)\n",
    "            ###\n",
    "            if ok:\n",
    "\n",
    "                temp_state = tuple(temp_board.flatten())\n",
    "\n",
    "                temp_states.append(temp_board.reshape(25,))\n",
    "\n",
    "                pos_moves.append((from_pos, move))\n",
    "\n",
    "                ####################################################################################\n",
    "\n",
    "                #############################################\n",
    "\n",
    "#                for from_pos_op, move_op in ALL_MOVES:\n",
    "#\n",
    "#                    ###\n",
    "#                    if (temp_state, from_pos_op, move_op) in self.state_move_to_state:\n",
    "#                        temp_board_op = self.state_move_to_state[(temp_state, from_pos_op, move_op)]\n",
    "#                        ok = True\n",
    "#                    else:\n",
    "#                        temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\n",
    "#                        self.state_move_to_state[(temp_state, from_pos_op, move_op)] = temp_board_op\n",
    "#                    #temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\n",
    "#                    ###\n",
    "#                    if ok:\n",
    "#\n",
    "#                        temp_state_op = tuple(temp_board_op.flatten())\n",
    "#\n",
    "#                        v_temp.append(self.calc_value(temp_state_op))\n",
    "#\n",
    "#                if len(v_temp) != 0: v_temp = np.min(v_temp)\n",
    "#                else: v_temp = 1 # to encourage exploration\n",
    "#\n",
    "#                if v_temp > v:\n",
    "#                    temp_pos_move_list = [(from_pos, move)]\n",
    "#                    v = v_temp\n",
    "#                elif v_temp == v:\n",
    "#                    temp_pos_move_list.append((from_pos, move))\n",
    "\n",
    "                #############################################\n",
    "\n",
    "#                v_temp = self.calc_value(temp_state)\n",
    "#                if v_temp > v:\n",
    "#                    temp_pos_move_list = [(from_pos, move)]\n",
    "#                    v = v_temp\n",
    "#                elif v_temp == v:\n",
    "#                    temp_pos_move_list.append((from_pos, move))\n",
    "\n",
    "                ####################################################################################\n",
    "\n",
    "        values = self.calc_value(np.array(temp_states).reshape(-1, 25))\n",
    "\n",
    "        for v_temp, pos_move in zip(values, pos_moves):\n",
    "\n",
    "            if v_temp > v:\n",
    "                temp_pos_move_list = [pos_move]\n",
    "                v = v_temp\n",
    "            elif v_temp == v: temp_pos_move_list.append(pos_move) \n",
    "\n",
    "        new_state = random.choice(temp_pos_move_list)\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def reward(self, winner):\n",
    "        if winner == self.player_id:\n",
    "            R = 1\n",
    "        elif winner == -1:\n",
    "            R = 0\n",
    "        else:\n",
    "            R = -1\n",
    "        return R\n",
    "\n",
    "    def learn_state(self, state):\n",
    "\n",
    "        winner = self.dummy.check_winner_board(np.array(state).reshape(5, 5))\n",
    "\n",
    "        target = self.calc_target(state, winner)\n",
    "\n",
    "        self.train_model(target, 10) # 10\n",
    "\n",
    "        self.prev_state = state\n",
    "\n",
    "    def calc_value(self, state_array):\n",
    "        return self.value_model.predict(state_array, verbose= 0)\n",
    "\n",
    "    def calc_target(self, state, winner):\n",
    "\n",
    "        if self.player_id in state:\n",
    "\n",
    "            v_s = self.calc_value(np.array(self.prev_state).reshape(1, 25))\n",
    "\n",
    "            R = self.reward(winner)\n",
    "\n",
    "            if winner == -1: v_s_tag = self.calc_value(np.array(state).reshape(1, 25))\n",
    "            else: v_s_tag = 0\n",
    "\n",
    "            target = np.array(v_s + self.alpha * (R + v_s_tag - v_s))\n",
    "\n",
    "            return target\n",
    "\n",
    "    def train_model(self, target, epochs):\n",
    "\n",
    "        X_train = np.array(self.prev_state).reshape(1, 25)\n",
    "\n",
    "        if target is not None: self.value_model.fit(X_train, target, epochs=epochs, verbose=0)\n",
    "\n",
    "    def train(self, n_games= 10000):\n",
    "\n",
    "        for _ in tqdm(range(n_games)):\n",
    "\n",
    "            board = np.ones((5, 5), dtype= np.uint8) * -1\n",
    "            state = tuple(board.flatten())\n",
    "\n",
    "            winner = -1\n",
    "            while winner == -1:\n",
    "\n",
    "                #print('move')\n",
    "\n",
    "                ######## S\n",
    "                #simmetry = check_simmetries(board, self.states_dict)\n",
    "                #if simmetry is None: \n",
    "                #    self.states_dict[state] = [0, 0, []]\n",
    "                #    id_simmetry = None\n",
    "                #else: state, id_simmetry = simmetry\n",
    "                #if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\n",
    "                ######## S\n",
    "                \n",
    "                from_pos, move = self.make_move_and_learn(state)\n",
    "\n",
    "                ######## S\n",
    "                #if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\n",
    "                ######## S\n",
    "\n",
    "                board, ok = self.dummy.single_move(board, from_pos, move, 0)\n",
    "\n",
    "                state = tuple(board.flatten())\n",
    "\n",
    "                winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "                if winner == -1:\n",
    "\n",
    "                    from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                    board, ok = self.dummy.single_move(board, from_pos, move, 1)\n",
    "                    while not ok:\n",
    "                        from_pos, move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "                        board, ok = self.dummy.single_move(board, from_pos, move, 1)\n",
    "\n",
    "                    state = tuple(board.flatten())\n",
    "\n",
    "                    winner = self.dummy.check_winner_board(board)\n",
    "\n",
    "            self.learn_state(state)\n",
    "            self.learn_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_81 (Dense)            (None, 2)                 52        \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "init done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:07<13:05,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:10<17:58, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ThePlayer \u001b[38;5;241m=\u001b[39m DeepQAgent(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mThePlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      6\u001b[0m player1 \u001b[38;5;241m=\u001b[39m ThePlayer\n",
      "Cell \u001b[1;32mIn[97], line 280\u001b[0m, in \u001b[0;36mDeepQAgent.train\u001b[1;34m(self, n_games)\u001b[0m\n\u001b[0;32m    266\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m winner \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    268\u001b[0m \n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m#print('move')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m#if state not in self.states_dict: self.states_dict[state] = [0, 0, []]\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     from_pos, move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_move_and_learn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m#if id_simmetry is not None: from_pos, move = inverse_simmetries[id_simmetry](from_pos, move)\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m######## S\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     board, ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdummy\u001b[38;5;241m.\u001b[39msingle_move(board, from_pos, move, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[97], line 59\u001b[0m, in \u001b[0;36mDeepQAgent.make_move_and_learn\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_state(state)\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_move_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[97], line 49\u001b[0m, in \u001b[0;36mDeepQAgent.choose_move_train\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoose_move_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_factor: pos_move \u001b[38;5;241m=\u001b[39m ALL_MOVES[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, N_ALL)]\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: pos_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_optimal_move\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pos_move\n",
      "Cell \u001b[1;32mIn[97], line 112\u001b[0m, in \u001b[0;36mDeepQAgent.make_optimal_move\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    110\u001b[0m         counts\u001b[38;5;241m.\u001b[39mappend(count)\n\u001b[1;32m--> 112\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pos_moves)):\n",
      "Cell \u001b[1;32mIn[97], line 236\u001b[0m, in \u001b[0;36mDeepQAgent.calc_value\u001b[1;34m(self, state_array)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_array):\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py:2349\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2341\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2342\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2343\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2346\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2347\u001b[0m         )\n\u001b[1;32m-> 2349\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2357\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2360\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1583\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1260\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1259\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\data_adapter.py:307\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;66;03m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# performance.\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_batch_indices\u001b[39m(indices):\n\u001b[0;32m    310\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m      A Dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2237\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2238\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     41\u001b[0m       input_dataset,\n\u001b[0;32m     42\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[0;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    255\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m    233\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    234\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    235\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 202\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    204\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_arg_keywords \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    233\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    235\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    240\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    168\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 169\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\data_adapter.py:297\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.permutation\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpermutation\u001b[39m(_):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# It turns out to be more performant to make a new set of indices\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;66;03m# rather than reusing the same range Tensor. (presumably because of\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m# buffer forwarding.)\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mand\u001b[39;00m shuffle \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m         indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(indices)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2153\u001b[0m, in \u001b[0;36mrange\u001b[1;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m, [start, limit, delta]) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[0;32m   2152\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(start, ops\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m-> 2153\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2154\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(limit, ops\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   2155\u001b[0m     limit \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(limit, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:1642\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1633\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1634\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1635\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1639\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1642\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1645\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    173\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\constant_op.py:290\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    288\u001b[0m dtype_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtensor_value\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    289\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: tensor_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value}\n\u001b[1;32m--> 290\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_callbacks\u001b[38;5;241m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m    294\u001b[0m   \u001b[38;5;66;03m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;66;03m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m   callback_outputs \u001b[38;5;241m=\u001b[39m op_callbacks\u001b[38;5;241m.\u001b[39minvoke_op_callbacks(\n\u001b[0;32m    297\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[38;5;241m=\u001b[39mname, graph\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\func_graph.py:707\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    705\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    706\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:3814\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3814\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3815\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3816\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3817\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3818\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3819\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3820\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3821\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3822\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3823\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:2112\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2109\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2112\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_c_op(c_op\u001b[38;5;241m=\u001b[39mc_op, g\u001b[38;5;241m=\u001b[39mg)\n\u001b[0;32m   2115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_op \u001b[38;5;241m=\u001b[39m original_op\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:1970\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1966\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1967\u001b[0m                                          serialized)\n\u001b[0;32m   1969\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ThePlayer = DeepQAgent(0)\n",
    "ThePlayer.train(100)\n",
    "\n",
    "#\n",
    "\n",
    "player1 = ThePlayer\n",
    "player2 = RandomPlayer()\n",
    "\n",
    "n_trials = 100\n",
    "wins_first = 0\n",
    "\n",
    "for _ in tqdm(range(n_trials)):\n",
    "    \n",
    "    g = Game()\n",
    "    winner = g.play(player1, player2)\n",
    "    if winner == 0: wins_first += 1\n",
    "\n",
    "print(f\"Player won {wins_first} / {n_trials} as first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(Player):\n",
    "\n",
    "    def __init__(self, player_id= 0, exploration_factor=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.exploration_factor =exploration_factor\n",
    "        self.epsilon = 0.1\n",
    "        self.alpha = 0.5\n",
    "\n",
    "        self.prev_state = tuple([-1 for _ in range(25)])\n",
    "        self.state = None\n",
    "\n",
    "        self.player_id = player_id\n",
    "        self.opponent_id = 1 - player_id\n",
    "\n",
    "        self.dummy = Dummy_Game()\n",
    "\n",
    "    def choose_move(self, game: 'Game') -> tuple[tuple[int, int], Move]:\n",
    "\n",
    "        board = game.get_board()\n",
    "        self.state = tuple(board.flatten())\n",
    " \n",
    "        if random.random() < self.exploration_factor: pos_move = ALL_MOVES[np.random.randint(0, N_ALL)]\n",
    "        else: pos_move = self.make_optimal_move(self.state)\n",
    "\n",
    "        return pos_move\n",
    "\n",
    "    def make_move_and_learn(self, state):\n",
    "\n",
    "        self.learn_state(state)\n",
    "\n",
    "        return self.make_move(state)\n",
    "\n",
    "    def make_optimal_move(self, state):\n",
    "\n",
    "        temp_state_list = []\n",
    "        v = -float('Inf')\n",
    "\n",
    "        board = np.array(state).reshape(5, 5)\n",
    "\n",
    "        for from_pos, move in ALL_MOVES:\n",
    "\n",
    "            v_temp = []\n",
    "\n",
    "            temp_board, ok = self.dummy.single_move(board, from_pos, move, self.player_id)\n",
    "            # could add check on ok for legal moves\n",
    "\n",
    "            temp_state = tuple(temp_board.flatten())\n",
    "\n",
    "            for from_pos_op, move_op in ALL_MOVES:\n",
    "                temp_board_op, ok = self.dummy.single_move(temp_board, from_pos_op, move_op, self.opponent_id)\n",
    "            # could add check on ok for legal moves\n",
    "\n",
    "                temp_state_op = tuple(temp_board_op.flatten())\n",
    "\n",
    "                v_temp.append(self.calc_value(temp_state_op))\n",
    "\n",
    "            # delets Nones\n",
    "            v_temp = list(filter(None.__ne__, v_temp))\n",
    "\n",
    "            if len(v_temp) != 0:\n",
    "                v_temp = np.min(v_temp)\n",
    "            else:\n",
    "                # encourage exploration\n",
    "                v_temp = 1\n",
    "\n",
    "            if v_temp > v:\n",
    "                temp_state_list = [temp_state]\n",
    "                v = v_temp\n",
    "            elif v_temp == v:\n",
    "                temp_state_list.append(temp_state)\n",
    "\n",
    "        try:\n",
    "            new_state = random.choice(temp_state_list)\n",
    "        except ValueError:\n",
    "            print('temp state:', temp_state_list)\n",
    "            raise Exception('temp state empty')\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def reward(self, winner):\n",
    "        if winner == self.player_id:\n",
    "            R = 1\n",
    "        elif winner == -1:\n",
    "            R = 0\n",
    "        else:\n",
    "            R = -1\n",
    "        return R\n",
    "\n",
    "class DeepAgent(Agent):\n",
    "\n",
    "    def __init__(self, tag, exploration_factor=1):\n",
    "        super().__init__(tag, exploration_factor)\n",
    "        self.tag = tag\n",
    "        self.value_model = self.load_model()\n",
    "\n",
    "    @staticmethod\n",
    "    def state2array(state):\n",
    "\n",
    "        num_state = []\n",
    "        for s in state:\n",
    "            if s == 'X':\n",
    "                num_state.append(1)\n",
    "            elif s == 'O':\n",
    "                num_state.append(-1)\n",
    "            else:\n",
    "                num_state.append(0)\n",
    "        num_state = np.array([num_state])\n",
    "        return num_state\n",
    "\n",
    "    def learn_state(self, state, winner):\n",
    "\n",
    "        target = self.calc_target(state, winner)\n",
    "\n",
    "        self.train_model(target, 10)\n",
    "\n",
    "        self.prev_state = state\n",
    "\n",
    "    def load_model(self):\n",
    "        s = 'model_values' + self.tag + '.h5'\n",
    "        model_file = Path(s)\n",
    "        if model_file.is_file():\n",
    "            model = Km.load_model(s)\n",
    "            print('load model: ' + s)\n",
    "        else:\n",
    "            print('new model')\n",
    "            model = Km.Sequential()\n",
    "            model.add(Kl.Dense(18, activation='relu', input_dim=9))\n",
    "            model.add(Kl.Dense(18, activation='relu'))\n",
    "            model.add(Kl.Dense(1, activation='linear'))\n",
    "            model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def calc_value(self, state):\n",
    "        return self.value_model.predict(self.state2array(state))\n",
    "\n",
    "    def calc_target(self, state, winner):\n",
    "\n",
    "        if self.tag in state:\n",
    "\n",
    "            v_s = self.calc_value(self.prev_state)\n",
    "\n",
    "            R = self.reward(winner)\n",
    "\n",
    "            if winner is None:\n",
    "                v_s_tag = self.calc_value(state)\n",
    "            else:\n",
    "                v_s_tag = 0\n",
    "\n",
    "            target = np.array(v_s + self.alpha * (R + v_s_tag - v_s))\n",
    "\n",
    "            return target\n",
    "\n",
    "    def train_model(self, target, epochs):\n",
    "\n",
    "        X_train = self.state2array(self.prev_state)\n",
    "\n",
    "        if target is not None:\n",
    "            self.value_model.fit(X_train, target, epochs=epochs, verbose=0)\n",
    "\n",
    "\n",
    "def check_player():\n",
    "    # print('QAgent X 1 and QAgent 1 0')\n",
    "    # game = TicTacToe('QAgent', 'QAgent', 1, 0)\n",
    "    # game.play_to_learn(1000)\n",
    "    # print('DeepAgent X 0.8 and DeepAgent 0.8')\n",
    "    # game = TicTacToe('DeepAgent', 'DeepAgent', 0.8, 0.8)\n",
    "    # game.play_to_learn(30000)\n",
    "    print('DeepAgent X 0 and QAgent 1, 0')\n",
    "    game = TicTacToe('Player', 'DeepAgent', 0.8, 0.8)\n",
    "    game.play_game()\n",
    "\n",
    "\n",
    "check_player()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
